{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hareevarshan\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('football_Pvalue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_type</th>\n",
       "      <th>Player_position</th>\n",
       "      <th>Duration_mins</th>\n",
       "      <th>Load</th>\n",
       "      <th>RTT_minus_1</th>\n",
       "      <th>RTT</th>\n",
       "      <th>RTT_plus_1</th>\n",
       "      <th>distance_z1</th>\n",
       "      <th>distance_z3</th>\n",
       "      <th>distance_z4</th>\n",
       "      <th>...</th>\n",
       "      <th>MetabolicPowerZone3Distance</th>\n",
       "      <th>MetabolicPowerZone4Distance</th>\n",
       "      <th>MetabolicPowerZone5Distance</th>\n",
       "      <th>MetabolicPowerZone6Distance</th>\n",
       "      <th>MetabolicPowerZone2Time</th>\n",
       "      <th>MetabolicPowerZone4Time</th>\n",
       "      <th>MetabolicPowerZone5Time</th>\n",
       "      <th>MetabolicPowerZone6Time</th>\n",
       "      <th>HighIntensityBurstNumber</th>\n",
       "      <th>RPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>374.85</td>\n",
       "      <td>41.58</td>\n",
       "      <td>42.89</td>\n",
       "      <td>...</td>\n",
       "      <td>60.34</td>\n",
       "      <td>53.01</td>\n",
       "      <td>44.53</td>\n",
       "      <td>11.61</td>\n",
       "      <td>174.2</td>\n",
       "      <td>18.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.93</td>\n",
       "      <td>410.55</td>\n",
       "      <td>36.36</td>\n",
       "      <td>15.00</td>\n",
       "      <td>...</td>\n",
       "      <td>65.80</td>\n",
       "      <td>53.35</td>\n",
       "      <td>39.26</td>\n",
       "      <td>12.88</td>\n",
       "      <td>171.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1963.77</td>\n",
       "      <td>828.10</td>\n",
       "      <td>462.98</td>\n",
       "      <td>...</td>\n",
       "      <td>680.65</td>\n",
       "      <td>721.60</td>\n",
       "      <td>533.76</td>\n",
       "      <td>193.19</td>\n",
       "      <td>1068.7</td>\n",
       "      <td>217.6</td>\n",
       "      <td>133.4</td>\n",
       "      <td>41.1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>192.26</td>\n",
       "      <td>291.09</td>\n",
       "      <td>54.44</td>\n",
       "      <td>...</td>\n",
       "      <td>224.14</td>\n",
       "      <td>236.30</td>\n",
       "      <td>93.05</td>\n",
       "      <td>5.03</td>\n",
       "      <td>101.1</td>\n",
       "      <td>71.1</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>411.36</td>\n",
       "      <td>118.90</td>\n",
       "      <td>32.45</td>\n",
       "      <td>...</td>\n",
       "      <td>37.09</td>\n",
       "      <td>72.40</td>\n",
       "      <td>58.73</td>\n",
       "      <td>11.82</td>\n",
       "      <td>126.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Session_type  Player_position  Duration_mins  Load  RTT_minus_1   RTT  \\\n",
       "0  Pitch Session                6             80   320         0.77  0.79   \n",
       "1  Pitch Session                2             80   320         0.72  0.78   \n",
       "2  Pitch Session                2             80   320         0.68  0.81   \n",
       "3  Pitch Session                2             80   320         0.68  0.81   \n",
       "4  Pitch Session                2             80   320         0.68  0.81   \n",
       "\n",
       "   RTT_plus_1  distance_z1  distance_z3  distance_z4 ...   \\\n",
       "0        0.77       374.85        41.58        42.89 ...    \n",
       "1        0.93       410.55        36.36        15.00 ...    \n",
       "2        0.78      1963.77       828.10       462.98 ...    \n",
       "3        0.78       192.26       291.09        54.44 ...    \n",
       "4        0.78       411.36       118.90        32.45 ...    \n",
       "\n",
       "   MetabolicPowerZone3Distance  MetabolicPowerZone4Distance  \\\n",
       "0                        60.34                        53.01   \n",
       "1                        65.80                        53.35   \n",
       "2                       680.65                       721.60   \n",
       "3                       224.14                       236.30   \n",
       "4                        37.09                        72.40   \n",
       "\n",
       "   MetabolicPowerZone5Distance  MetabolicPowerZone6Distance  \\\n",
       "0                        44.53                        11.61   \n",
       "1                        39.26                        12.88   \n",
       "2                       533.76                       193.19   \n",
       "3                        93.05                         5.03   \n",
       "4                        58.73                        11.82   \n",
       "\n",
       "   MetabolicPowerZone2Time  MetabolicPowerZone4Time  MetabolicPowerZone5Time  \\\n",
       "0                    174.2                     18.5                     12.0   \n",
       "1                    171.5                     22.0                     13.0   \n",
       "2                   1068.7                    217.6                    133.4   \n",
       "3                    101.1                     71.1                     24.2   \n",
       "4                    126.0                     22.4                     16.0   \n",
       "\n",
       "   MetabolicPowerZone6Time  HighIntensityBurstNumber  RPE  \n",
       "0                      2.6                         2    4  \n",
       "1                      3.7                         1    4  \n",
       "2                     41.1                         1    4  \n",
       "3                      1.2                         0    4  \n",
       "4                      3.1                         0    4  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pitch Session', 6, 80, 320, 0.77, 0.79, 0.77, 374.85, 41.58,\n",
       "       42.89, 7.57, 0.83, 6.05, 26.91, 6.19, 0.0, 53.05, 4.19, 4.98,\n",
       "       29.96, 60.1, 160.3, 0.0, 0.0, 11, 14, 0, 4, 84, 126, 74, 539.81,\n",
       "       169.01, 356.93, 282.91, 62.51, 146.15, 339.32, 3.82, 55, 14, 1, 0,\n",
       "       64.0, 4.62, 49.87, 56.14, 720.71, 4.809375, 6.771875, 133.35,\n",
       "       235.99, 60.34, 53.01, 44.53, 11.61, 174.2, 18.5, 12.0, 2.6, 2],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['RPE'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "X[:, 0] = labelencoder.fit_transform(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16568, 63) (16568,) (4143, 63) (4143,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dense(units=30, kernel_initializer = 'uniform', activation = 'relu', input_dim=63))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(BatchNormalization(momentum=0.99, epsilon=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dense(units=30, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "regressor.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                1920      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 3,121\n",
      "Trainable params: 3,001\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16568 samples, validate on 4143 samples\n",
      "Epoch 1/300\n",
      "16568/16568 [==============================] - 2s 96us/step - loss: 17.7842 - val_loss: 2.8815\n",
      "Epoch 2/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 2.6346 - val_loss: 73.8656\n",
      "Epoch 3/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 2.0392 - val_loss: 17.2520\n",
      "Epoch 4/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 1.6925 - val_loss: 4.0044\n",
      "Epoch 5/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 1.4551 - val_loss: 1.2141\n",
      "Epoch 6/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 1.3301 - val_loss: 1.9669\n",
      "Epoch 7/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 1.1526 - val_loss: 3.4158\n",
      "Epoch 8/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 1.1705 - val_loss: 14.9066\n",
      "Epoch 9/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 1.0538 - val_loss: 2.3103\n",
      "Epoch 10/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 1.0393 - val_loss: 3.3556\n",
      "Epoch 11/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.9643 - val_loss: 0.6400\n",
      "Epoch 12/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.9718 - val_loss: 1.1090\n",
      "Epoch 13/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.9308 - val_loss: 3.4032\n",
      "Epoch 14/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.8940 - val_loss: 4.0242\n",
      "Epoch 15/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.8792 - val_loss: 2.8807\n",
      "Epoch 16/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.8626 - val_loss: 8.6629\n",
      "Epoch 17/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.8120 - val_loss: 4.4618\n",
      "Epoch 18/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.8237 - val_loss: 25.8318\n",
      "Epoch 19/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.8239 - val_loss: 3.8386\n",
      "Epoch 20/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.7877 - val_loss: 1.8493\n",
      "Epoch 21/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.7609 - val_loss: 0.5617\n",
      "Epoch 22/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.7135 - val_loss: 0.4770\n",
      "Epoch 23/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.7494 - val_loss: 0.4058\n",
      "Epoch 24/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.7542 - val_loss: 0.6337\n",
      "Epoch 25/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.7233 - val_loss: 0.4631\n",
      "Epoch 26/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.7345 - val_loss: 0.9930\n",
      "Epoch 27/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.7259 - val_loss: 0.4462\n",
      "Epoch 28/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.6763 - val_loss: 1.2741\n",
      "Epoch 29/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.7523 - val_loss: 0.4111\n",
      "Epoch 30/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.6959 - val_loss: 0.8790\n",
      "Epoch 31/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.6769 - val_loss: 0.4303\n",
      "Epoch 32/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.7093 - val_loss: 0.4352\n",
      "Epoch 33/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.6658 - val_loss: 1.0579\n",
      "Epoch 34/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.7662 - val_loss: 1.2113\n",
      "Epoch 35/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.6260 - val_loss: 0.3012\n",
      "Epoch 36/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.6617 - val_loss: 0.4016\n",
      "Epoch 37/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.6901 - val_loss: 0.4112\n",
      "Epoch 38/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.6624 - val_loss: 0.5818\n",
      "Epoch 39/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.6149 - val_loss: 0.3437\n",
      "Epoch 40/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.6298 - val_loss: 0.5174\n",
      "Epoch 41/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.6339 - val_loss: 0.5142\n",
      "Epoch 42/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.6117 - val_loss: 0.3631\n",
      "Epoch 43/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.6257 - val_loss: 0.5924\n",
      "Epoch 44/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.5949 - val_loss: 0.5401\n",
      "Epoch 45/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.5755 - val_loss: 0.6751\n",
      "Epoch 46/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.6003 - val_loss: 0.6445\n",
      "Epoch 47/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.5881 - val_loss: 0.9072\n",
      "Epoch 48/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.5725 - val_loss: 0.4899\n",
      "Epoch 49/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.5542 - val_loss: 0.4283\n",
      "Epoch 50/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.5806 - val_loss: 1.8060\n",
      "Epoch 51/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.5550 - val_loss: 0.3843\n",
      "Epoch 52/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.5486 - val_loss: 0.2254\n",
      "Epoch 53/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.5631 - val_loss: 0.4841\n",
      "Epoch 54/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.5502 - val_loss: 0.5090\n",
      "Epoch 55/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.5375 - val_loss: 0.4517\n",
      "Epoch 56/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.5292 - val_loss: 0.8234\n",
      "Epoch 57/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.5438 - val_loss: 0.3315\n",
      "Epoch 58/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.5872 - val_loss: 0.4838\n",
      "Epoch 59/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4997 - val_loss: 0.5785\n",
      "Epoch 60/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.5249 - val_loss: 0.5504\n",
      "Epoch 61/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.5278 - val_loss: 0.6400\n",
      "Epoch 62/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4993 - val_loss: 0.5878\n",
      "Epoch 63/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4958 - val_loss: 0.4203\n",
      "Epoch 64/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.5207 - val_loss: 0.2519\n",
      "Epoch 65/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4961 - val_loss: 0.9349\n",
      "Epoch 66/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4973 - val_loss: 0.5510\n",
      "Epoch 67/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.5133 - val_loss: 0.2692\n",
      "Epoch 68/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4682 - val_loss: 0.4473\n",
      "Epoch 69/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4543 - val_loss: 0.3745\n",
      "Epoch 70/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4924 - val_loss: 0.2379\n",
      "Epoch 71/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4583 - val_loss: 1.3358\n",
      "Epoch 72/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4767 - val_loss: 0.5057\n",
      "Epoch 73/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4763 - val_loss: 0.4337\n",
      "Epoch 74/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.5424 - val_loss: 0.8370\n",
      "Epoch 75/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.5370 - val_loss: 0.8522\n",
      "Epoch 76/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4943 - val_loss: 0.7888\n",
      "Epoch 77/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4929 - val_loss: 0.6895\n",
      "Epoch 78/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4870 - val_loss: 0.3506\n",
      "Epoch 79/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4529 - val_loss: 0.3181\n",
      "Epoch 80/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.5027 - val_loss: 0.4370\n",
      "Epoch 81/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.5199 - val_loss: 0.9502\n",
      "Epoch 82/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4673 - val_loss: 1.0051\n",
      "Epoch 83/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4455 - val_loss: 1.6280\n",
      "Epoch 84/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.5284 - val_loss: 0.5792\n",
      "Epoch 85/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4795 - val_loss: 0.7169\n",
      "Epoch 86/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4659 - val_loss: 0.2750\n",
      "Epoch 87/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4588 - val_loss: 0.4934\n",
      "Epoch 88/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4247 - val_loss: 0.4891\n",
      "Epoch 89/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4569 - val_loss: 0.3976\n",
      "Epoch 90/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4347 - val_loss: 2.1355\n",
      "Epoch 91/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4505 - val_loss: 0.3159\n",
      "Epoch 92/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4679 - val_loss: 0.8616\n",
      "Epoch 93/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4390 - val_loss: 1.2490\n",
      "Epoch 94/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4772 - val_loss: 0.4076\n",
      "Epoch 95/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4171 - val_loss: 1.1601\n",
      "Epoch 96/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4499 - val_loss: 0.5681\n",
      "Epoch 97/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4523 - val_loss: 1.3130\n",
      "Epoch 98/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4530 - val_loss: 0.9217\n",
      "Epoch 99/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4392 - val_loss: 0.8990\n",
      "Epoch 100/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4131 - val_loss: 0.5360\n",
      "Epoch 101/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4198 - val_loss: 0.5807\n",
      "Epoch 102/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.4236 - val_loss: 0.5852\n",
      "Epoch 103/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4083 - val_loss: 0.5437\n",
      "Epoch 104/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4192 - val_loss: 0.3935\n",
      "Epoch 105/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4250 - val_loss: 0.2227\n",
      "Epoch 106/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4184 - val_loss: 0.4239\n",
      "Epoch 107/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.4311 - val_loss: 1.5513\n",
      "Epoch 108/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4540 - val_loss: 1.9230\n",
      "Epoch 109/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.4535 - val_loss: 0.7440\n",
      "Epoch 110/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.4504 - val_loss: 0.9180\n",
      "Epoch 111/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.4549 - val_loss: 0.6314\n",
      "Epoch 112/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4332 - val_loss: 1.2806\n",
      "Epoch 113/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3984 - val_loss: 0.6235\n",
      "Epoch 114/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.4170 - val_loss: 0.7839\n",
      "Epoch 115/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.4135 - val_loss: 0.6125\n",
      "Epoch 116/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.4205 - val_loss: 0.5021\n",
      "Epoch 117/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4176 - val_loss: 0.8113\n",
      "Epoch 118/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.4195 - val_loss: 0.8473\n",
      "Epoch 119/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.4253 - val_loss: 0.6567\n",
      "Epoch 120/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.4160 - val_loss: 1.1575\n",
      "Epoch 121/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.4283 - val_loss: 0.5881\n",
      "Epoch 122/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3902 - val_loss: 0.5977\n",
      "Epoch 123/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4079 - val_loss: 6.4406\n",
      "Epoch 124/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.4058 - val_loss: 1.3758\n",
      "Epoch 125/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3818 - val_loss: 0.6408\n",
      "Epoch 126/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3675 - val_loss: 0.5947\n",
      "Epoch 127/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.3924 - val_loss: 0.6520\n",
      "Epoch 128/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3796 - val_loss: 0.3622\n",
      "Epoch 129/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3900 - val_loss: 0.5354\n",
      "Epoch 130/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3681 - val_loss: 0.7521\n",
      "Epoch 131/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3923 - val_loss: 0.4349\n",
      "Epoch 132/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3799 - val_loss: 0.8392\n",
      "Epoch 133/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4357 - val_loss: 0.8133\n",
      "Epoch 134/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4306 - val_loss: 1.0457\n",
      "Epoch 135/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4429 - val_loss: 0.7596\n",
      "Epoch 136/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4040 - val_loss: 0.9041\n",
      "Epoch 137/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4045 - val_loss: 1.0042\n",
      "Epoch 138/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4107 - val_loss: 2.2196\n",
      "Epoch 139/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3910 - val_loss: 1.5017\n",
      "Epoch 140/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3928 - val_loss: 0.7999\n",
      "Epoch 141/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3741 - val_loss: 2.7881\n",
      "Epoch 142/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3628 - val_loss: 0.7692\n",
      "Epoch 143/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3937 - val_loss: 1.0371\n",
      "Epoch 144/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3895 - val_loss: 0.6833\n",
      "Epoch 145/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3514 - val_loss: 0.9150\n",
      "Epoch 146/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4262 - val_loss: 3.2823\n",
      "Epoch 147/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4006 - val_loss: 1.3281\n",
      "Epoch 148/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4263 - val_loss: 0.4527\n",
      "Epoch 149/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3970 - val_loss: 0.4273\n",
      "Epoch 150/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3963 - val_loss: 0.5237\n",
      "Epoch 151/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3876 - val_loss: 0.5408\n",
      "Epoch 152/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3839 - val_loss: 0.6262\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3876 - val_loss: 0.4679\n",
      "Epoch 154/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.4136 - val_loss: 1.0188\n",
      "Epoch 155/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3874 - val_loss: 0.3321\n",
      "Epoch 156/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4019 - val_loss: 0.3324\n",
      "Epoch 157/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4249 - val_loss: 0.1852\n",
      "Epoch 158/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3872 - val_loss: 0.4907\n",
      "Epoch 159/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4004 - val_loss: 0.3112\n",
      "Epoch 160/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3789 - val_loss: 0.4978\n",
      "Epoch 161/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4017 - val_loss: 0.8182\n",
      "Epoch 162/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4117 - val_loss: 0.3889\n",
      "Epoch 163/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3855 - val_loss: 0.7244\n",
      "Epoch 164/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4242 - val_loss: 0.4095\n",
      "Epoch 165/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3928 - val_loss: 0.3272\n",
      "Epoch 166/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3839 - val_loss: 0.5522\n",
      "Epoch 167/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4196 - val_loss: 0.5644\n",
      "Epoch 168/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3895 - val_loss: 0.3404\n",
      "Epoch 169/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3939 - val_loss: 0.6336\n",
      "Epoch 170/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4068 - val_loss: 0.7387\n",
      "Epoch 171/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3891 - val_loss: 0.3968\n",
      "Epoch 172/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3723 - val_loss: 0.8087\n",
      "Epoch 173/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.4294 - val_loss: 0.6680\n",
      "Epoch 174/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3697 - val_loss: 0.3212\n",
      "Epoch 175/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.4028 - val_loss: 0.4610\n",
      "Epoch 176/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3700 - val_loss: 0.9584\n",
      "Epoch 177/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3733 - val_loss: 0.3830\n",
      "Epoch 178/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3655 - val_loss: 0.6619\n",
      "Epoch 179/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3512 - val_loss: 0.6580\n",
      "Epoch 180/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3722 - val_loss: 0.2206\n",
      "Epoch 181/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3800 - val_loss: 0.4420\n",
      "Epoch 182/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3671 - val_loss: 0.6955\n",
      "Epoch 183/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3613 - val_loss: 0.3758\n",
      "Epoch 184/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3784 - val_loss: 0.6108\n",
      "Epoch 185/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3717 - val_loss: 0.2129\n",
      "Epoch 186/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3596 - val_loss: 0.2053\n",
      "Epoch 187/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3618 - val_loss: 0.2620\n",
      "Epoch 188/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3792 - val_loss: 0.3879\n",
      "Epoch 189/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3935 - val_loss: 0.4292\n",
      "Epoch 190/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3920 - val_loss: 0.6272\n",
      "Epoch 191/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3686 - val_loss: 0.4108\n",
      "Epoch 192/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3900 - val_loss: 0.2621\n",
      "Epoch 193/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3658 - val_loss: 1.1309\n",
      "Epoch 194/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3907 - val_loss: 0.5676\n",
      "Epoch 195/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3793 - val_loss: 0.6301\n",
      "Epoch 196/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.3841 - val_loss: 0.4329\n",
      "Epoch 197/300\n",
      "16568/16568 [==============================] - 1s 45us/step - loss: 0.4014 - val_loss: 0.5831\n",
      "Epoch 198/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3965 - val_loss: 0.4158\n",
      "Epoch 199/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3891 - val_loss: 0.6112\n",
      "Epoch 200/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.3820 - val_loss: 0.3274\n",
      "Epoch 201/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.3599 - val_loss: 0.8636\n",
      "Epoch 202/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3666 - val_loss: 0.6887\n",
      "Epoch 203/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.3726 - val_loss: 0.3166\n",
      "Epoch 204/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3618 - val_loss: 1.1640\n",
      "Epoch 205/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3586 - val_loss: 0.3816\n",
      "Epoch 206/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3597 - val_loss: 1.0146\n",
      "Epoch 207/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3984 - val_loss: 0.2556\n",
      "Epoch 208/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3503 - val_loss: 0.6354\n",
      "Epoch 209/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3807 - val_loss: 0.3356\n",
      "Epoch 210/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3759 - val_loss: 0.6474\n",
      "Epoch 211/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.3511 - val_loss: 0.5274\n",
      "Epoch 212/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3761 - val_loss: 0.3468\n",
      "Epoch 213/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3537 - val_loss: 0.5468\n",
      "Epoch 214/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3851 - val_loss: 0.3674\n",
      "Epoch 215/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3616 - val_loss: 0.3858\n",
      "Epoch 216/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3553 - val_loss: 0.3401\n",
      "Epoch 217/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3463 - val_loss: 0.4382\n",
      "Epoch 218/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3660 - val_loss: 0.3225\n",
      "Epoch 219/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3539 - val_loss: 0.4914\n",
      "Epoch 220/300\n",
      "16568/16568 [==============================] - 1s 45us/step - loss: 0.3318 - val_loss: 0.3934\n",
      "Epoch 221/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3634 - val_loss: 0.4490\n",
      "Epoch 222/300\n",
      "16568/16568 [==============================] - 1s 45us/step - loss: 0.3454 - val_loss: 0.4697\n",
      "Epoch 223/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3414 - val_loss: 0.4225\n",
      "Epoch 224/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3511 - val_loss: 0.1849\n",
      "Epoch 225/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3768 - val_loss: 0.3358\n",
      "Epoch 226/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3733 - val_loss: 0.3648\n",
      "Epoch 227/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3565 - val_loss: 0.3640\n",
      "Epoch 228/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3700 - val_loss: 0.3050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/300\n",
      "16568/16568 [==============================] - 1s 45us/step - loss: 0.3653 - val_loss: 1.1730\n",
      "Epoch 230/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3425 - val_loss: 0.1794\n",
      "Epoch 231/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3397 - val_loss: 0.2591\n",
      "Epoch 232/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.3410 - val_loss: 0.4114\n",
      "Epoch 233/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3659 - val_loss: 0.2805\n",
      "Epoch 234/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.3766 - val_loss: 0.2267\n",
      "Epoch 235/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3864 - val_loss: 0.7311\n",
      "Epoch 236/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3689 - val_loss: 0.2296\n",
      "Epoch 237/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3725 - val_loss: 0.2370\n",
      "Epoch 238/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3841 - val_loss: 0.4829\n",
      "Epoch 239/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3748 - val_loss: 0.2599\n",
      "Epoch 240/300\n",
      "16568/16568 [==============================] - 1s 45us/step - loss: 0.3615 - val_loss: 0.3104\n",
      "Epoch 241/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3668 - val_loss: 0.3518\n",
      "Epoch 242/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3341 - val_loss: 0.4152\n",
      "Epoch 243/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3227 - val_loss: 0.3375\n",
      "Epoch 244/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3368 - val_loss: 0.2076\n",
      "Epoch 245/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3805 - val_loss: 0.2453\n",
      "Epoch 246/300\n",
      "16568/16568 [==============================] - 1s 46us/step - loss: 0.3488 - val_loss: 0.5199\n",
      "Epoch 247/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3476 - val_loss: 0.2857\n",
      "Epoch 248/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3456 - val_loss: 0.5079\n",
      "Epoch 249/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3666 - val_loss: 0.4244\n",
      "Epoch 250/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3426 - val_loss: 0.3278\n",
      "Epoch 251/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3541 - val_loss: 0.3356\n",
      "Epoch 252/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3527 - val_loss: 0.3663\n",
      "Epoch 253/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3626 - val_loss: 0.2521\n",
      "Epoch 254/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3537 - val_loss: 0.4296\n",
      "Epoch 255/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3466 - val_loss: 0.4213\n",
      "Epoch 256/300\n",
      "16568/16568 [==============================] - 1s 46us/step - loss: 0.3431 - val_loss: 0.3449\n",
      "Epoch 257/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3669 - val_loss: 0.2346\n",
      "Epoch 258/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.3160 - val_loss: 0.4191\n",
      "Epoch 259/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3263 - val_loss: 0.2938\n",
      "Epoch 260/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3344 - val_loss: 0.2419\n",
      "Epoch 261/300\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3456 - val_loss: 0.2737\n",
      "Epoch 262/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3522 - val_loss: 0.4183\n",
      "Epoch 263/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3469 - val_loss: 0.3537\n",
      "Epoch 264/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3210 - val_loss: 0.2643\n",
      "Epoch 265/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3338 - val_loss: 0.2606\n",
      "Epoch 266/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.3311 - val_loss: 0.3908\n",
      "Epoch 267/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3342 - val_loss: 0.5189\n",
      "Epoch 268/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3311 - val_loss: 0.4887\n",
      "Epoch 269/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3383 - val_loss: 0.2114\n",
      "Epoch 270/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3388 - val_loss: 0.3129\n",
      "Epoch 271/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3257 - val_loss: 0.2022\n",
      "Epoch 272/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3355 - val_loss: 0.4873\n",
      "Epoch 273/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3505 - val_loss: 0.3890\n",
      "Epoch 274/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3402 - val_loss: 0.4446\n",
      "Epoch 275/300\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.3273 - val_loss: 0.4614\n",
      "Epoch 276/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3334 - val_loss: 0.2965\n",
      "Epoch 277/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3233 - val_loss: 0.2185\n",
      "Epoch 278/300\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.3319 - val_loss: 0.3709\n",
      "Epoch 279/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3370 - val_loss: 1.1166\n",
      "Epoch 280/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3421 - val_loss: 0.4178\n",
      "Epoch 281/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3358 - val_loss: 0.3966\n",
      "Epoch 282/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4064 - val_loss: 0.1728\n",
      "Epoch 283/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3650 - val_loss: 0.1989\n",
      "Epoch 284/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3401 - val_loss: 0.2967\n",
      "Epoch 285/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3406 - val_loss: 0.2805\n",
      "Epoch 286/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3489 - val_loss: 0.3249\n",
      "Epoch 287/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3540 - val_loss: 0.5986\n",
      "Epoch 288/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3400 - val_loss: 0.7841\n",
      "Epoch 289/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3513 - val_loss: 0.4372\n",
      "Epoch 290/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3214 - val_loss: 0.4686\n",
      "Epoch 291/300\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3613 - val_loss: 0.2680\n",
      "Epoch 292/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3221 - val_loss: 0.2427\n",
      "Epoch 293/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3570 - val_loss: 0.3937\n",
      "Epoch 294/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3762 - val_loss: 1.0029\n",
      "Epoch 295/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3717 - val_loss: 0.4787\n",
      "Epoch 296/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3492 - val_loss: 0.2597\n",
      "Epoch 297/300\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3402 - val_loss: 0.3048\n",
      "Epoch 298/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3348 - val_loss: 0.3771\n",
      "Epoch 299/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3458 - val_loss: 0.3959\n",
      "Epoch 300/300\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3443 - val_loss: 0.3392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2120ab6b4e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x = X_train, y = y_train, epochs = 300, batch_size = 32,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 0s 22us/step\n",
      "Loss = 0.3392350407411245\n"
     ]
    }
   ],
   "source": [
    "prediction = regressor.evaluate(x = X_test, y = y_test)\n",
    "print (\"Loss = \" + str(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.7796683 ],\n",
       "       [ 8.055178  ],\n",
       "       [ 7.1084857 ],\n",
       "       [ 8.106271  ],\n",
       "       [ 5.0269976 ],\n",
       "       [ 5.2747087 ],\n",
       "       [-0.74293184],\n",
       "       [ 8.939023  ],\n",
       "       [ 4.1025095 ],\n",
       "       [ 7.2232223 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3392350429091212"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9175682879008149"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9185690149011076"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13880491256713867"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
