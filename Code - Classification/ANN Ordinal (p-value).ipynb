{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hareevarshan\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('football_Pvalue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_type</th>\n",
       "      <th>Player_position</th>\n",
       "      <th>Duration_mins</th>\n",
       "      <th>Load</th>\n",
       "      <th>RTT_minus_1</th>\n",
       "      <th>RTT</th>\n",
       "      <th>RTT_plus_1</th>\n",
       "      <th>distance_z1</th>\n",
       "      <th>distance_z3</th>\n",
       "      <th>distance_z4</th>\n",
       "      <th>...</th>\n",
       "      <th>MetabolicPowerZone3Distance</th>\n",
       "      <th>MetabolicPowerZone4Distance</th>\n",
       "      <th>MetabolicPowerZone5Distance</th>\n",
       "      <th>MetabolicPowerZone6Distance</th>\n",
       "      <th>MetabolicPowerZone2Time</th>\n",
       "      <th>MetabolicPowerZone4Time</th>\n",
       "      <th>MetabolicPowerZone5Time</th>\n",
       "      <th>MetabolicPowerZone6Time</th>\n",
       "      <th>HighIntensityBurstNumber</th>\n",
       "      <th>RPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.77</td>\n",
       "      <td>374.85</td>\n",
       "      <td>41.58</td>\n",
       "      <td>42.89</td>\n",
       "      <td>...</td>\n",
       "      <td>60.34</td>\n",
       "      <td>53.01</td>\n",
       "      <td>44.53</td>\n",
       "      <td>11.61</td>\n",
       "      <td>174.2</td>\n",
       "      <td>18.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.93</td>\n",
       "      <td>410.55</td>\n",
       "      <td>36.36</td>\n",
       "      <td>15.00</td>\n",
       "      <td>...</td>\n",
       "      <td>65.80</td>\n",
       "      <td>53.35</td>\n",
       "      <td>39.26</td>\n",
       "      <td>12.88</td>\n",
       "      <td>171.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1963.77</td>\n",
       "      <td>828.10</td>\n",
       "      <td>462.98</td>\n",
       "      <td>...</td>\n",
       "      <td>680.65</td>\n",
       "      <td>721.60</td>\n",
       "      <td>533.76</td>\n",
       "      <td>193.19</td>\n",
       "      <td>1068.7</td>\n",
       "      <td>217.6</td>\n",
       "      <td>133.4</td>\n",
       "      <td>41.1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>192.26</td>\n",
       "      <td>291.09</td>\n",
       "      <td>54.44</td>\n",
       "      <td>...</td>\n",
       "      <td>224.14</td>\n",
       "      <td>236.30</td>\n",
       "      <td>93.05</td>\n",
       "      <td>5.03</td>\n",
       "      <td>101.1</td>\n",
       "      <td>71.1</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>411.36</td>\n",
       "      <td>118.90</td>\n",
       "      <td>32.45</td>\n",
       "      <td>...</td>\n",
       "      <td>37.09</td>\n",
       "      <td>72.40</td>\n",
       "      <td>58.73</td>\n",
       "      <td>11.82</td>\n",
       "      <td>126.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Session_type  Player_position  Duration_mins  Load  RTT_minus_1   RTT  \\\n",
       "0  Pitch Session                6             80   320         0.77  0.79   \n",
       "1  Pitch Session                2             80   320         0.72  0.78   \n",
       "2  Pitch Session                2             80   320         0.68  0.81   \n",
       "3  Pitch Session                2             80   320         0.68  0.81   \n",
       "4  Pitch Session                2             80   320         0.68  0.81   \n",
       "\n",
       "   RTT_plus_1  distance_z1  distance_z3  distance_z4 ...   \\\n",
       "0        0.77       374.85        41.58        42.89 ...    \n",
       "1        0.93       410.55        36.36        15.00 ...    \n",
       "2        0.78      1963.77       828.10       462.98 ...    \n",
       "3        0.78       192.26       291.09        54.44 ...    \n",
       "4        0.78       411.36       118.90        32.45 ...    \n",
       "\n",
       "   MetabolicPowerZone3Distance  MetabolicPowerZone4Distance  \\\n",
       "0                        60.34                        53.01   \n",
       "1                        65.80                        53.35   \n",
       "2                       680.65                       721.60   \n",
       "3                       224.14                       236.30   \n",
       "4                        37.09                        72.40   \n",
       "\n",
       "   MetabolicPowerZone5Distance  MetabolicPowerZone6Distance  \\\n",
       "0                        44.53                        11.61   \n",
       "1                        39.26                        12.88   \n",
       "2                       533.76                       193.19   \n",
       "3                        93.05                         5.03   \n",
       "4                        58.73                        11.82   \n",
       "\n",
       "   MetabolicPowerZone2Time  MetabolicPowerZone4Time  MetabolicPowerZone5Time  \\\n",
       "0                    174.2                     18.5                     12.0   \n",
       "1                    171.5                     22.0                     13.0   \n",
       "2                   1068.7                    217.6                    133.4   \n",
       "3                    101.1                     71.1                     24.2   \n",
       "4                    126.0                     22.4                     16.0   \n",
       "\n",
       "   MetabolicPowerZone6Time  HighIntensityBurstNumber  RPE  \n",
       "0                      2.6                         2    4  \n",
       "1                      3.7                         1    4  \n",
       "2                     41.1                         1    4  \n",
       "3                      1.2                         0    4  \n",
       "4                      3.1                         0    4  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset['RTT_plus_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_type</th>\n",
       "      <th>Player_position</th>\n",
       "      <th>Duration_mins</th>\n",
       "      <th>Load</th>\n",
       "      <th>RTT_minus_1</th>\n",
       "      <th>RTT</th>\n",
       "      <th>distance_z1</th>\n",
       "      <th>distance_z3</th>\n",
       "      <th>distance_z4</th>\n",
       "      <th>distance_z5</th>\n",
       "      <th>...</th>\n",
       "      <th>MetabolicPowerZone3Distance</th>\n",
       "      <th>MetabolicPowerZone4Distance</th>\n",
       "      <th>MetabolicPowerZone5Distance</th>\n",
       "      <th>MetabolicPowerZone6Distance</th>\n",
       "      <th>MetabolicPowerZone2Time</th>\n",
       "      <th>MetabolicPowerZone4Time</th>\n",
       "      <th>MetabolicPowerZone5Time</th>\n",
       "      <th>MetabolicPowerZone6Time</th>\n",
       "      <th>HighIntensityBurstNumber</th>\n",
       "      <th>RPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>374.85</td>\n",
       "      <td>41.58</td>\n",
       "      <td>42.89</td>\n",
       "      <td>7.57</td>\n",
       "      <td>...</td>\n",
       "      <td>60.34</td>\n",
       "      <td>53.01</td>\n",
       "      <td>44.53</td>\n",
       "      <td>11.61</td>\n",
       "      <td>174.2</td>\n",
       "      <td>18.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>410.55</td>\n",
       "      <td>36.36</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>65.80</td>\n",
       "      <td>53.35</td>\n",
       "      <td>39.26</td>\n",
       "      <td>12.88</td>\n",
       "      <td>171.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1963.77</td>\n",
       "      <td>828.10</td>\n",
       "      <td>462.98</td>\n",
       "      <td>210.79</td>\n",
       "      <td>...</td>\n",
       "      <td>680.65</td>\n",
       "      <td>721.60</td>\n",
       "      <td>533.76</td>\n",
       "      <td>193.19</td>\n",
       "      <td>1068.7</td>\n",
       "      <td>217.6</td>\n",
       "      <td>133.4</td>\n",
       "      <td>41.1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>192.26</td>\n",
       "      <td>291.09</td>\n",
       "      <td>54.44</td>\n",
       "      <td>21.94</td>\n",
       "      <td>...</td>\n",
       "      <td>224.14</td>\n",
       "      <td>236.30</td>\n",
       "      <td>93.05</td>\n",
       "      <td>5.03</td>\n",
       "      <td>101.1</td>\n",
       "      <td>71.1</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>411.36</td>\n",
       "      <td>118.90</td>\n",
       "      <td>32.45</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>37.09</td>\n",
       "      <td>72.40</td>\n",
       "      <td>58.73</td>\n",
       "      <td>11.82</td>\n",
       "      <td>126.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Session_type  Player_position  Duration_mins  Load  RTT_minus_1   RTT  \\\n",
       "0  Pitch Session                6             80   320         0.77  0.79   \n",
       "1  Pitch Session                2             80   320         0.72  0.78   \n",
       "2  Pitch Session                2             80   320         0.68  0.81   \n",
       "3  Pitch Session                2             80   320         0.68  0.81   \n",
       "4  Pitch Session                2             80   320         0.68  0.81   \n",
       "\n",
       "   distance_z1  distance_z3  distance_z4  distance_z5 ...   \\\n",
       "0       374.85        41.58        42.89         7.57 ...    \n",
       "1       410.55        36.36        15.00         0.00 ...    \n",
       "2      1963.77       828.10       462.98       210.79 ...    \n",
       "3       192.26       291.09        54.44        21.94 ...    \n",
       "4       411.36       118.90        32.45         0.56 ...    \n",
       "\n",
       "   MetabolicPowerZone3Distance  MetabolicPowerZone4Distance  \\\n",
       "0                        60.34                        53.01   \n",
       "1                        65.80                        53.35   \n",
       "2                       680.65                       721.60   \n",
       "3                       224.14                       236.30   \n",
       "4                        37.09                        72.40   \n",
       "\n",
       "   MetabolicPowerZone5Distance  MetabolicPowerZone6Distance  \\\n",
       "0                        44.53                        11.61   \n",
       "1                        39.26                        12.88   \n",
       "2                       533.76                       193.19   \n",
       "3                        93.05                         5.03   \n",
       "4                        58.73                        11.82   \n",
       "\n",
       "   MetabolicPowerZone2Time  MetabolicPowerZone4Time  MetabolicPowerZone5Time  \\\n",
       "0                    174.2                     18.5                     12.0   \n",
       "1                    171.5                     22.0                     13.0   \n",
       "2                   1068.7                    217.6                    133.4   \n",
       "3                    101.1                     71.1                     24.2   \n",
       "4                    126.0                     22.4                     16.0   \n",
       "\n",
       "   MetabolicPowerZone6Time  HighIntensityBurstNumber  RPE  \n",
       "0                      2.6                         2    4  \n",
       "1                      3.7                         1    4  \n",
       "2                     41.1                         1    4  \n",
       "3                      1.2                         0    4  \n",
       "4                      3.1                         0    4  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Session_type</th>\n",
       "      <th>Player_position</th>\n",
       "      <th>Duration_mins</th>\n",
       "      <th>Load</th>\n",
       "      <th>RTT_minus_1</th>\n",
       "      <th>RTT</th>\n",
       "      <th>distance_z1</th>\n",
       "      <th>distance_z3</th>\n",
       "      <th>distance_z4</th>\n",
       "      <th>distance_z5</th>\n",
       "      <th>...</th>\n",
       "      <th>RPE_1</th>\n",
       "      <th>RPE_2</th>\n",
       "      <th>RPE_3</th>\n",
       "      <th>RPE_4</th>\n",
       "      <th>RPE_5</th>\n",
       "      <th>RPE_6</th>\n",
       "      <th>RPE_7</th>\n",
       "      <th>RPE_8</th>\n",
       "      <th>RPE_9</th>\n",
       "      <th>RPE_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>374.85</td>\n",
       "      <td>41.58</td>\n",
       "      <td>42.89</td>\n",
       "      <td>7.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.78</td>\n",
       "      <td>410.55</td>\n",
       "      <td>36.36</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1963.77</td>\n",
       "      <td>828.10</td>\n",
       "      <td>462.98</td>\n",
       "      <td>210.79</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>192.26</td>\n",
       "      <td>291.09</td>\n",
       "      <td>54.44</td>\n",
       "      <td>21.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>320</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>411.36</td>\n",
       "      <td>118.90</td>\n",
       "      <td>32.45</td>\n",
       "      <td>0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Session_type  Player_position  Duration_mins  Load  RTT_minus_1   RTT  \\\n",
       "0  Pitch Session                6             80   320         0.77  0.79   \n",
       "1  Pitch Session                2             80   320         0.72  0.78   \n",
       "2  Pitch Session                2             80   320         0.68  0.81   \n",
       "3  Pitch Session                2             80   320         0.68  0.81   \n",
       "4  Pitch Session                2             80   320         0.68  0.81   \n",
       "\n",
       "   distance_z1  distance_z3  distance_z4  distance_z5   ...    RPE_1  RPE_2  \\\n",
       "0       374.85        41.58        42.89         7.57   ...        0      0   \n",
       "1       410.55        36.36        15.00         0.00   ...        0      0   \n",
       "2      1963.77       828.10       462.98       210.79   ...        0      0   \n",
       "3       192.26       291.09        54.44        21.94   ...        0      0   \n",
       "4       411.36       118.90        32.45         0.56   ...        0      0   \n",
       "\n",
       "   RPE_3  RPE_4  RPE_5  RPE_6  RPE_7  RPE_8  RPE_9  RPE_10  \n",
       "0      0      1      0      0      0      0      0       0  \n",
       "1      0      1      0      0      0      0      0       0  \n",
       "2      0      1      0      0      0      0      0       0  \n",
       "3      0      1      0      0      0      0      0       0  \n",
       "4      0      1      0      0      0      0      0       0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"RPE\"] =dataset[\"RPE\"].astype(int)\n",
    "dataset = pd.get_dummies(dataset, columns=[\"RPE\"])\n",
    "dataset.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20711, 71)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:60].values # first columns\n",
    "y = dataset.iloc[:,61:].values # last columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pitch Session', 6, 80, 320, 0.77, 0.79, 374.85, 41.58, 42.89,\n",
       "       7.57, 0.83, 6.05, 26.91, 6.19, 0.0, 53.05, 4.19, 4.98, 29.96, 60.1,\n",
       "       160.3, 0.0, 0.0, 11, 14, 0, 4, 84, 126, 74, 539.81, 169.01, 356.93,\n",
       "       282.91, 62.51, 146.15, 339.32, 3.82, 55, 14, 1, 0, 64.0, 4.62,\n",
       "       49.87, 56.14, 720.71, 4.809375, 6.771875, 133.35, 235.99, 60.34,\n",
       "       53.01, 44.53, 11.61, 174.2, 18.5, 12.0, 2.6, 2], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "X[:, 0] = labelencoder.fit_transform(X[:, 0])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.      ,   0.      ,   0.      ,   1.      ,   6.      ,\n",
       "        80.      , 320.      ,   0.77    ,   0.79    , 374.85    ,\n",
       "        41.58    ,  42.89    ,   7.57    ,   0.83    ,   6.05    ,\n",
       "        26.91    ,   6.19    ,   0.      ,  53.05    ,   4.19    ,\n",
       "         4.98    ,  29.96    ,  60.1     , 160.3     ,   0.      ,\n",
       "         0.      ,  11.      ,  14.      ,   0.      ,   4.      ,\n",
       "        84.      , 126.      ,  74.      , 539.81    , 169.01    ,\n",
       "       356.93    , 282.91    ,  62.51    , 146.15    , 339.32    ,\n",
       "         3.82    ,  55.      ,  14.      ,   1.      ,   0.      ,\n",
       "        64.      ,   4.62    ,  49.87    ,  56.14    , 720.71    ,\n",
       "         4.809375,   6.771875, 133.35    , 235.99    ,  60.34    ,\n",
       "        53.01    ,  44.53    ,  11.61    , 174.2     ,  18.5     ,\n",
       "        12.      ,   2.6     ,   2.      ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.normalize(X, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16568, 62) (16568, 10) (4143, 62) (4143, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=30, kernel_initializer = 'uniform', activation = 'relu', input_dim=62))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=30, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n",
    "classifier.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=40, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n",
    "classifier.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(10,bias_initializer='zeros'))\n",
    "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n",
    "classifier.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                1890      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 40)                1240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,910\n",
      "Trainable params: 4,690\n",
      "Non-trainable params: 220\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = \"categorical_crossentropy\", metrics = [\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16568 samples, validate on 4143 samples\n",
      "Epoch 1/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2103 - categorical_accuracy: 0.9203 - val_loss: 5.1210 - val_categorical_accuracy: 0.0258\n",
      "Epoch 2/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2357 - categorical_accuracy: 0.9102 - val_loss: 3.9657 - val_categorical_accuracy: 0.1429\n",
      "Epoch 3/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2433 - categorical_accuracy: 0.9095 - val_loss: 0.2300 - val_categorical_accuracy: 0.8933\n",
      "Epoch 4/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2173 - categorical_accuracy: 0.9154 - val_loss: 14.0708 - val_categorical_accuracy: 0.0082\n",
      "Epoch 5/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2117 - categorical_accuracy: 0.9160 - val_loss: 2.8515 - val_categorical_accuracy: 0.1376\n",
      "Epoch 6/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2295 - categorical_accuracy: 0.9113 - val_loss: 6.1780 - val_categorical_accuracy: 0.0275\n",
      "Epoch 7/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2341 - categorical_accuracy: 0.9088 - val_loss: 2.0649 - val_categorical_accuracy: 0.3980\n",
      "Epoch 8/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2343 - categorical_accuracy: 0.9104 - val_loss: 0.6134 - val_categorical_accuracy: 0.6853\n",
      "Epoch 9/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2194 - categorical_accuracy: 0.9168 - val_loss: 0.3696 - val_categorical_accuracy: 0.8952\n",
      "Epoch 10/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2254 - categorical_accuracy: 0.9142 - val_loss: 6.1107 - val_categorical_accuracy: 0.0113\n",
      "Epoch 11/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2251 - categorical_accuracy: 0.9150 - val_loss: 11.2373 - val_categorical_accuracy: 0.0084\n",
      "Epoch 12/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2122 - categorical_accuracy: 0.9178 - val_loss: 6.1473 - val_categorical_accuracy: 0.0101\n",
      "Epoch 13/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2376 - categorical_accuracy: 0.9092 - val_loss: 0.5236 - val_categorical_accuracy: 0.7758\n",
      "Epoch 14/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2297 - categorical_accuracy: 0.9135 - val_loss: 0.0429 - val_categorical_accuracy: 0.9792\n",
      "Epoch 15/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2320 - categorical_accuracy: 0.9116 - val_loss: 13.6053 - val_categorical_accuracy: 0.0094\n",
      "Epoch 16/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2226 - categorical_accuracy: 0.9161 - val_loss: 2.7043 - val_categorical_accuracy: 0.4294\n",
      "Epoch 17/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2683 - categorical_accuracy: 0.9000 - val_loss: 6.1397 - val_categorical_accuracy: 0.0710\n",
      "Epoch 18/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2240 - categorical_accuracy: 0.9155 - val_loss: 13.7573 - val_categorical_accuracy: 0.0080\n",
      "Epoch 19/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2350 - categorical_accuracy: 0.9111 - val_loss: 0.6536 - val_categorical_accuracy: 0.6416\n",
      "Epoch 20/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.2327 - categorical_accuracy: 0.9101 - val_loss: 9.1996 - val_categorical_accuracy: 0.0683\n",
      "Epoch 21/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2296 - categorical_accuracy: 0.9131 - val_loss: 0.3638 - val_categorical_accuracy: 0.8477\n",
      "Epoch 22/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2236 - categorical_accuracy: 0.9150 - val_loss: 0.3109 - val_categorical_accuracy: 0.8494\n",
      "Epoch 23/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2198 - categorical_accuracy: 0.9150 - val_loss: 0.4778 - val_categorical_accuracy: 0.7854\n",
      "Epoch 24/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2014 - categorical_accuracy: 0.9229 - val_loss: 13.7653 - val_categorical_accuracy: 0.0075\n",
      "Epoch 25/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2495 - categorical_accuracy: 0.9061 - val_loss: 3.2731 - val_categorical_accuracy: 0.1716\n",
      "Epoch 26/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2264 - categorical_accuracy: 0.9140 - val_loss: 3.9076 - val_categorical_accuracy: 0.1294\n",
      "Epoch 27/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.2330 - categorical_accuracy: 0.9112 - val_loss: 9.8535 - val_categorical_accuracy: 0.0094\n",
      "Epoch 28/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2428 - categorical_accuracy: 0.9063 - val_loss: 3.2188 - val_categorical_accuracy: 0.2718\n",
      "Epoch 29/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2103 - categorical_accuracy: 0.9174 - val_loss: 0.5211 - val_categorical_accuracy: 0.7572\n",
      "Epoch 30/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2218 - categorical_accuracy: 0.9154 - val_loss: 0.0668 - val_categorical_accuracy: 0.9826\n",
      "Epoch 31/200\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.2554 - categorical_accuracy: 0.9035 - val_loss: 3.1643 - val_categorical_accuracy: 0.2498\n",
      "Epoch 32/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2350 - categorical_accuracy: 0.9104 - val_loss: 11.5412 - val_categorical_accuracy: 0.0157\n",
      "Epoch 33/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2665 - categorical_accuracy: 0.8996 - val_loss: 5.1515 - val_categorical_accuracy: 0.0261\n",
      "Epoch 34/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2292 - categorical_accuracy: 0.9107 - val_loss: 0.7667 - val_categorical_accuracy: 0.6051\n",
      "Epoch 35/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2285 - categorical_accuracy: 0.9120 - val_loss: 0.5167 - val_categorical_accuracy: 0.7596\n",
      "Epoch 36/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2398 - categorical_accuracy: 0.9105 - val_loss: 2.7466 - val_categorical_accuracy: 0.3580\n",
      "Epoch 37/200\n",
      "16568/16568 [==============================] - ETA: 0s - loss: 0.2206 - categorical_accuracy: 0.91 - 1s 39us/step - loss: 0.2241 - categorical_accuracy: 0.9147 - val_loss: 0.9160 - val_categorical_accuracy: 0.6124\n",
      "Epoch 38/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2255 - categorical_accuracy: 0.9140 - val_loss: 1.3491 - val_categorical_accuracy: 0.4096\n",
      "Epoch 39/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.1994 - categorical_accuracy: 0.9233 - val_loss: 7.4144 - val_categorical_accuracy: 0.0258\n",
      "Epoch 40/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2229 - categorical_accuracy: 0.9147 - val_loss: 7.6811 - val_categorical_accuracy: 0.0140\n",
      "Epoch 41/200\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.2301 - categorical_accuracy: 0.9106 - val_loss: 0.7536 - val_categorical_accuracy: 0.6635\n",
      "Epoch 42/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.2221 - categorical_accuracy: 0.9153 - val_loss: 0.1009 - val_categorical_accuracy: 0.9467\n",
      "Epoch 43/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2255 - categorical_accuracy: 0.9142 - val_loss: 4.4301 - val_categorical_accuracy: 0.1250\n",
      "Epoch 44/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2277 - categorical_accuracy: 0.9118 - val_loss: 2.7130 - val_categorical_accuracy: 0.1600\n",
      "Epoch 45/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2217 - categorical_accuracy: 0.9160 - val_loss: 0.0979 - val_categorical_accuracy: 0.9505\n",
      "Epoch 46/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2215 - categorical_accuracy: 0.9137 - val_loss: 0.8685 - val_categorical_accuracy: 0.8554\n",
      "Epoch 47/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2582 - categorical_accuracy: 0.9063 - val_loss: 5.2672 - val_categorical_accuracy: 0.1716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2221 - categorical_accuracy: 0.9153 - val_loss: 1.1170 - val_categorical_accuracy: 0.4721\n",
      "Epoch 49/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2520 - categorical_accuracy: 0.9075 - val_loss: 5.7583 - val_categorical_accuracy: 0.0434\n",
      "Epoch 50/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2432 - categorical_accuracy: 0.9096 - val_loss: 10.6843 - val_categorical_accuracy: 0.0251\n",
      "Epoch 51/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2594 - categorical_accuracy: 0.9058 - val_loss: 2.6337 - val_categorical_accuracy: 0.3558\n",
      "Epoch 52/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2236 - categorical_accuracy: 0.9144 - val_loss: 2.6620 - val_categorical_accuracy: 0.3599\n",
      "Epoch 53/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2140 - categorical_accuracy: 0.9186 - val_loss: 1.3014 - val_categorical_accuracy: 0.5648\n",
      "Epoch 54/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2134 - categorical_accuracy: 0.9162 - val_loss: 7.7527 - val_categorical_accuracy: 0.0316\n",
      "Epoch 55/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2377 - categorical_accuracy: 0.9082 - val_loss: 10.5387 - val_categorical_accuracy: 0.0099\n",
      "Epoch 56/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2562 - categorical_accuracy: 0.9054 - val_loss: 0.4374 - val_categorical_accuracy: 0.8064\n",
      "Epoch 57/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2324 - categorical_accuracy: 0.9107 - val_loss: 2.0705 - val_categorical_accuracy: 0.3109\n",
      "Epoch 58/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2152 - categorical_accuracy: 0.9151 - val_loss: 14.0086 - val_categorical_accuracy: 0.0251\n",
      "Epoch 59/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2110 - categorical_accuracy: 0.9173 - val_loss: 13.1723 - val_categorical_accuracy: 0.0080\n",
      "Epoch 60/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2278 - categorical_accuracy: 0.9114 - val_loss: 13.3957 - val_categorical_accuracy: 0.0080\n",
      "Epoch 61/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2239 - categorical_accuracy: 0.9147 - val_loss: 1.0950 - val_categorical_accuracy: 0.5226\n",
      "Epoch 62/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2090 - categorical_accuracy: 0.9194 - val_loss: 7.4091 - val_categorical_accuracy: 0.0266\n",
      "Epoch 63/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2165 - categorical_accuracy: 0.9151 - val_loss: 15.6161 - val_categorical_accuracy: 0.0070\n",
      "Epoch 64/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2300 - categorical_accuracy: 0.9147 - val_loss: 1.2364 - val_categorical_accuracy: 0.5846\n",
      "Epoch 65/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2216 - categorical_accuracy: 0.9139 - val_loss: 3.2148 - val_categorical_accuracy: 0.0507\n",
      "Epoch 66/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2277 - categorical_accuracy: 0.9118 - val_loss: 1.2863 - val_categorical_accuracy: 0.4856\n",
      "Epoch 67/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2413 - categorical_accuracy: 0.9092 - val_loss: 2.5903 - val_categorical_accuracy: 0.1883\n",
      "Epoch 68/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2127 - categorical_accuracy: 0.9182 - val_loss: 0.3144 - val_categorical_accuracy: 0.8682\n",
      "Epoch 69/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2136 - categorical_accuracy: 0.9182 - val_loss: 0.5462 - val_categorical_accuracy: 0.7229\n",
      "Epoch 70/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2183 - categorical_accuracy: 0.9175 - val_loss: 2.9157 - val_categorical_accuracy: 0.2754\n",
      "Epoch 71/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2094 - categorical_accuracy: 0.9190 - val_loss: 11.1227 - val_categorical_accuracy: 0.0087\n",
      "Epoch 72/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2222 - categorical_accuracy: 0.9157 - val_loss: 4.8246 - val_categorical_accuracy: 0.0384\n",
      "Epoch 73/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2122 - categorical_accuracy: 0.9157 - val_loss: 3.9786 - val_categorical_accuracy: 0.2259\n",
      "Epoch 74/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2405 - categorical_accuracy: 0.9071 - val_loss: 3.4112 - val_categorical_accuracy: 0.2018\n",
      "Epoch 75/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2299 - categorical_accuracy: 0.9119 - val_loss: 0.0816 - val_categorical_accuracy: 0.9696\n",
      "Epoch 76/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2321 - categorical_accuracy: 0.9131 - val_loss: 12.8331 - val_categorical_accuracy: 0.0256\n",
      "Epoch 77/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2157 - categorical_accuracy: 0.9154 - val_loss: 2.2095 - val_categorical_accuracy: 0.2814\n",
      "Epoch 78/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2298 - categorical_accuracy: 0.9122 - val_loss: 13.3957 - val_categorical_accuracy: 0.0089\n",
      "Epoch 79/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2183 - categorical_accuracy: 0.9174 - val_loss: 2.6343 - val_categorical_accuracy: 0.2455\n",
      "Epoch 80/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2308 - categorical_accuracy: 0.9140 - val_loss: 10.9354 - val_categorical_accuracy: 0.0094\n",
      "Epoch 81/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2314 - categorical_accuracy: 0.9095 - val_loss: 12.9232 - val_categorical_accuracy: 0.0101\n",
      "Epoch 82/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2231 - categorical_accuracy: 0.9139 - val_loss: 3.8846 - val_categorical_accuracy: 0.1422\n",
      "Epoch 83/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2011 - categorical_accuracy: 0.9188 - val_loss: 1.5068 - val_categorical_accuracy: 0.5445\n",
      "Epoch 84/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2125 - categorical_accuracy: 0.9217 - val_loss: 10.4025 - val_categorical_accuracy: 0.0104\n",
      "Epoch 85/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2010 - categorical_accuracy: 0.9249 - val_loss: 0.1349 - val_categorical_accuracy: 0.9302\n",
      "Epoch 86/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2533 - categorical_accuracy: 0.9057 - val_loss: 2.8402 - val_categorical_accuracy: 0.3092\n",
      "Epoch 87/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2196 - categorical_accuracy: 0.9166 - val_loss: 0.7556 - val_categorical_accuracy: 0.7101\n",
      "Epoch 88/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2378 - categorical_accuracy: 0.9092 - val_loss: 2.5252 - val_categorical_accuracy: 0.1919\n",
      "Epoch 89/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2048 - categorical_accuracy: 0.9197 - val_loss: 0.0478 - val_categorical_accuracy: 0.9792\n",
      "Epoch 90/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2250 - categorical_accuracy: 0.9155 - val_loss: 2.3909 - val_categorical_accuracy: 0.4779\n",
      "Epoch 91/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2357 - categorical_accuracy: 0.9081 - val_loss: 1.2834 - val_categorical_accuracy: 0.4726\n",
      "Epoch 92/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2215 - categorical_accuracy: 0.9171 - val_loss: 0.2299 - val_categorical_accuracy: 0.9172\n",
      "Epoch 93/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2209 - categorical_accuracy: 0.9134 - val_loss: 0.2179 - val_categorical_accuracy: 0.8825\n",
      "Epoch 94/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.1960 - categorical_accuracy: 0.9219 - val_loss: 7.4299 - val_categorical_accuracy: 0.1996\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2252 - categorical_accuracy: 0.9133 - val_loss: 3.7253 - val_categorical_accuracy: 0.0731\n",
      "Epoch 96/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2199 - categorical_accuracy: 0.9150 - val_loss: 9.0983 - val_categorical_accuracy: 0.0251\n",
      "Epoch 97/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2079 - categorical_accuracy: 0.9201 - val_loss: 14.6524 - val_categorical_accuracy: 0.0251\n",
      "Epoch 98/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2182 - categorical_accuracy: 0.9165 - val_loss: 4.7758 - val_categorical_accuracy: 0.0299\n",
      "Epoch 99/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2627 - categorical_accuracy: 0.9011 - val_loss: 2.1528 - val_categorical_accuracy: 0.3681\n",
      "Epoch 100/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2304 - categorical_accuracy: 0.9118 - val_loss: 4.8825 - val_categorical_accuracy: 0.0205\n",
      "Epoch 101/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2283 - categorical_accuracy: 0.9122 - val_loss: 0.1941 - val_categorical_accuracy: 0.9083\n",
      "Epoch 102/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2191 - categorical_accuracy: 0.9167 - val_loss: 0.0763 - val_categorical_accuracy: 0.9599\n",
      "Epoch 103/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2422 - categorical_accuracy: 0.9080 - val_loss: 1.6372 - val_categorical_accuracy: 0.4260\n",
      "Epoch 104/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2270 - categorical_accuracy: 0.9121 - val_loss: 15.3635 - val_categorical_accuracy: 0.0080\n",
      "Epoch 105/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2132 - categorical_accuracy: 0.9185 - val_loss: 7.2055 - val_categorical_accuracy: 0.0116\n",
      "Epoch 106/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2321 - categorical_accuracy: 0.9114 - val_loss: 13.5375 - val_categorical_accuracy: 0.0251\n",
      "Epoch 107/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2285 - categorical_accuracy: 0.9128 - val_loss: 7.8384 - val_categorical_accuracy: 0.0251\n",
      "Epoch 108/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.2226 - categorical_accuracy: 0.9171 - val_loss: 0.3304 - val_categorical_accuracy: 0.8728\n",
      "Epoch 109/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2261 - categorical_accuracy: 0.9134 - val_loss: 4.2632 - val_categorical_accuracy: 0.0294\n",
      "Epoch 110/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2229 - categorical_accuracy: 0.9136 - val_loss: 5.4762 - val_categorical_accuracy: 0.0263\n",
      "Epoch 111/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2288 - categorical_accuracy: 0.9099 - val_loss: 4.4658 - val_categorical_accuracy: 0.0985\n",
      "Epoch 112/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2110 - categorical_accuracy: 0.9175 - val_loss: 2.2371 - val_categorical_accuracy: 0.3876\n",
      "Epoch 113/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2046 - categorical_accuracy: 0.9211 - val_loss: 12.4118 - val_categorical_accuracy: 0.0263\n",
      "Epoch 114/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2257 - categorical_accuracy: 0.9136 - val_loss: 2.8790 - val_categorical_accuracy: 0.2112\n",
      "Epoch 115/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2207 - categorical_accuracy: 0.9166 - val_loss: 2.8658 - val_categorical_accuracy: 0.2380\n",
      "Epoch 116/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2130 - categorical_accuracy: 0.9175 - val_loss: 2.4474 - val_categorical_accuracy: 0.3852\n",
      "Epoch 117/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.2191 - categorical_accuracy: 0.9147 - val_loss: 0.1301 - val_categorical_accuracy: 0.9380\n",
      "Epoch 118/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2092 - categorical_accuracy: 0.9156 - val_loss: 7.2878 - val_categorical_accuracy: 0.0768\n",
      "Epoch 119/200\n",
      "16568/16568 [==============================] - 1s 36us/step - loss: 0.2672 - categorical_accuracy: 0.9020 - val_loss: 0.2810 - val_categorical_accuracy: 0.8981\n",
      "Epoch 120/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2225 - categorical_accuracy: 0.9129 - val_loss: 7.1832 - val_categorical_accuracy: 0.0258\n",
      "Epoch 121/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2146 - categorical_accuracy: 0.9163 - val_loss: 3.0177 - val_categorical_accuracy: 0.3739\n",
      "Epoch 122/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2294 - categorical_accuracy: 0.9130 - val_loss: 1.8730 - val_categorical_accuracy: 0.2508\n",
      "Epoch 123/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2168 - categorical_accuracy: 0.9191 - val_loss: 10.8496 - val_categorical_accuracy: 0.0099\n",
      "Epoch 124/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2109 - categorical_accuracy: 0.9201 - val_loss: 0.5663 - val_categorical_accuracy: 0.7569\n",
      "Epoch 125/200\n",
      "16568/16568 [==============================] - 1s 45us/step - loss: 0.2478 - categorical_accuracy: 0.9067 - val_loss: 14.6705 - val_categorical_accuracy: 0.0302\n",
      "Epoch 126/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.1967 - categorical_accuracy: 0.9238 - val_loss: 0.4664 - val_categorical_accuracy: 0.7816\n",
      "Epoch 127/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.2141 - categorical_accuracy: 0.9175 - val_loss: 1.1489 - val_categorical_accuracy: 0.6715\n",
      "Epoch 128/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.2270 - categorical_accuracy: 0.9110 - val_loss: 7.7858 - val_categorical_accuracy: 0.0263\n",
      "Epoch 129/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2243 - categorical_accuracy: 0.9139 - val_loss: 15.3472 - val_categorical_accuracy: 0.0075\n",
      "Epoch 130/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2092 - categorical_accuracy: 0.9193 - val_loss: 2.1889 - val_categorical_accuracy: 0.5479\n",
      "Epoch 131/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2071 - categorical_accuracy: 0.9202 - val_loss: 1.0033 - val_categorical_accuracy: 0.7046\n",
      "Epoch 132/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2232 - categorical_accuracy: 0.9128 - val_loss: 1.5510 - val_categorical_accuracy: 0.3290\n",
      "Epoch 133/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2445 - categorical_accuracy: 0.9083 - val_loss: 0.1217 - val_categorical_accuracy: 0.9496\n",
      "Epoch 134/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2040 - categorical_accuracy: 0.9213 - val_loss: 0.2219 - val_categorical_accuracy: 0.9172\n",
      "Epoch 135/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2041 - categorical_accuracy: 0.9215 - val_loss: 9.9099 - val_categorical_accuracy: 0.0092\n",
      "Epoch 136/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2526 - categorical_accuracy: 0.9036 - val_loss: 1.6804 - val_categorical_accuracy: 0.4651\n",
      "Epoch 137/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.2106 - categorical_accuracy: 0.9201 - val_loss: 8.9561 - val_categorical_accuracy: 0.1608\n",
      "Epoch 138/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2004 - categorical_accuracy: 0.9213 - val_loss: 2.6077 - val_categorical_accuracy: 0.2701\n",
      "Epoch 139/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2203 - categorical_accuracy: 0.9170 - val_loss: 14.6973 - val_categorical_accuracy: 0.0070\n",
      "Epoch 140/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2634 - categorical_accuracy: 0.9037 - val_loss: 0.6360 - val_categorical_accuracy: 0.7951\n",
      "Epoch 141/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.1945 - categorical_accuracy: 0.9229 - val_loss: 4.1532 - val_categorical_accuracy: 0.1089\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2031 - categorical_accuracy: 0.9214 - val_loss: 5.3479 - val_categorical_accuracy: 0.0319\n",
      "Epoch 143/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2304 - categorical_accuracy: 0.9113 - val_loss: 0.4219 - val_categorical_accuracy: 0.8448\n",
      "Epoch 144/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2185 - categorical_accuracy: 0.9162 - val_loss: 1.5117 - val_categorical_accuracy: 0.5494\n",
      "Epoch 145/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2168 - categorical_accuracy: 0.9181 - val_loss: 4.0541 - val_categorical_accuracy: 0.3640\n",
      "Epoch 146/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2138 - categorical_accuracy: 0.9168 - val_loss: 0.0641 - val_categorical_accuracy: 0.9766\n",
      "Epoch 147/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2166 - categorical_accuracy: 0.9169 - val_loss: 13.8063 - val_categorical_accuracy: 0.0077\n",
      "Epoch 148/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2224 - categorical_accuracy: 0.9137 - val_loss: 15.0151 - val_categorical_accuracy: 0.0070\n",
      "Epoch 149/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2127 - categorical_accuracy: 0.9144 - val_loss: 6.9011 - val_categorical_accuracy: 0.0982\n",
      "Epoch 150/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2161 - categorical_accuracy: 0.9152 - val_loss: 12.8197 - val_categorical_accuracy: 0.0369\n",
      "Epoch 151/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2072 - categorical_accuracy: 0.9207 - val_loss: 1.1127 - val_categorical_accuracy: 0.6032\n",
      "Epoch 152/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2519 - categorical_accuracy: 0.9048 - val_loss: 1.7941 - val_categorical_accuracy: 0.5851\n",
      "Epoch 153/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2072 - categorical_accuracy: 0.9188 - val_loss: 8.4248 - val_categorical_accuracy: 0.0104\n",
      "Epoch 154/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2261 - categorical_accuracy: 0.9144 - val_loss: 7.3353 - val_categorical_accuracy: 0.0965\n",
      "Epoch 155/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.1993 - categorical_accuracy: 0.9199 - val_loss: 3.5835 - val_categorical_accuracy: 0.1395\n",
      "Epoch 156/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2203 - categorical_accuracy: 0.9142 - val_loss: 13.0898 - val_categorical_accuracy: 0.0072\n",
      "Epoch 157/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2410 - categorical_accuracy: 0.9085 - val_loss: 8.6791 - val_categorical_accuracy: 0.0077\n",
      "Epoch 158/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2044 - categorical_accuracy: 0.9194 - val_loss: 6.7622 - val_categorical_accuracy: 0.0657\n",
      "Epoch 159/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2445 - categorical_accuracy: 0.9060 - val_loss: 2.5481 - val_categorical_accuracy: 0.2003\n",
      "Epoch 160/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2151 - categorical_accuracy: 0.9157 - val_loss: 8.0790 - val_categorical_accuracy: 0.0263\n",
      "Epoch 161/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2143 - categorical_accuracy: 0.9148 - val_loss: 8.5224 - val_categorical_accuracy: 0.0256\n",
      "Epoch 162/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2247 - categorical_accuracy: 0.9148 - val_loss: 11.4728 - val_categorical_accuracy: 0.0097\n",
      "Epoch 163/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2146 - categorical_accuracy: 0.9194 - val_loss: 8.7492 - val_categorical_accuracy: 0.0084\n",
      "Epoch 164/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2070 - categorical_accuracy: 0.9188 - val_loss: 0.2904 - val_categorical_accuracy: 0.8786\n",
      "Epoch 165/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2141 - categorical_accuracy: 0.9184 - val_loss: 2.9245 - val_categorical_accuracy: 0.2800\n",
      "Epoch 166/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2085 - categorical_accuracy: 0.9182 - val_loss: 0.5641 - val_categorical_accuracy: 0.7799\n",
      "Epoch 167/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2364 - categorical_accuracy: 0.9090 - val_loss: 0.4885 - val_categorical_accuracy: 0.8132\n",
      "Epoch 168/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2195 - categorical_accuracy: 0.9142 - val_loss: 1.3248 - val_categorical_accuracy: 0.6527\n",
      "Epoch 169/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2411 - categorical_accuracy: 0.9083 - val_loss: 3.9984 - val_categorical_accuracy: 0.0748\n",
      "Epoch 170/200\n",
      "16568/16568 [==============================] - 1s 36us/step - loss: 0.2197 - categorical_accuracy: 0.9143 - val_loss: 0.5013 - val_categorical_accuracy: 0.7664\n",
      "Epoch 171/200\n",
      "16568/16568 [==============================] - 1s 36us/step - loss: 0.2095 - categorical_accuracy: 0.9165 - val_loss: 1.9369 - val_categorical_accuracy: 0.5303\n",
      "Epoch 172/200\n",
      "16568/16568 [==============================] - 1s 36us/step - loss: 0.2086 - categorical_accuracy: 0.9169 - val_loss: 2.7843 - val_categorical_accuracy: 0.2283\n",
      "Epoch 173/200\n",
      "16568/16568 [==============================] - 1s 36us/step - loss: 0.2163 - categorical_accuracy: 0.9166 - val_loss: 13.1017 - val_categorical_accuracy: 0.0087\n",
      "Epoch 174/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2055 - categorical_accuracy: 0.9200 - val_loss: 0.6016 - val_categorical_accuracy: 0.7384\n",
      "Epoch 175/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2086 - categorical_accuracy: 0.9176 - val_loss: 2.0307 - val_categorical_accuracy: 0.5146\n",
      "Epoch 176/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2067 - categorical_accuracy: 0.9230 - val_loss: 0.1392 - val_categorical_accuracy: 0.9652\n",
      "Epoch 177/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.2097 - categorical_accuracy: 0.9166 - val_loss: 13.3204 - val_categorical_accuracy: 0.0603\n",
      "Epoch 178/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2081 - categorical_accuracy: 0.9203 - val_loss: 5.1042 - val_categorical_accuracy: 0.2725\n",
      "Epoch 179/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2081 - categorical_accuracy: 0.9197 - val_loss: 0.0413 - val_categorical_accuracy: 0.9761\n",
      "Epoch 180/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2099 - categorical_accuracy: 0.9169 - val_loss: 5.8893 - val_categorical_accuracy: 0.0364\n",
      "Epoch 181/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2136 - categorical_accuracy: 0.9201 - val_loss: 6.9518 - val_categorical_accuracy: 0.0150\n",
      "Epoch 182/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2124 - categorical_accuracy: 0.9173 - val_loss: 8.6169 - val_categorical_accuracy: 0.0101\n",
      "Epoch 183/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2143 - categorical_accuracy: 0.9157 - val_loss: 10.0537 - val_categorical_accuracy: 0.0251\n",
      "Epoch 184/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2130 - categorical_accuracy: 0.9154 - val_loss: 2.1104 - val_categorical_accuracy: 0.3338\n",
      "Epoch 185/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2367 - categorical_accuracy: 0.9074 - val_loss: 3.5312 - val_categorical_accuracy: 0.0268\n",
      "Epoch 186/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2035 - categorical_accuracy: 0.9196 - val_loss: 0.9849 - val_categorical_accuracy: 0.6003\n",
      "Epoch 187/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2210 - categorical_accuracy: 0.9125 - val_loss: 0.2870 - val_categorical_accuracy: 0.8204\n",
      "Epoch 188/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2224 - categorical_accuracy: 0.9134 - val_loss: 1.3721 - val_categorical_accuracy: 0.6326\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2357 - categorical_accuracy: 0.9080 - val_loss: 2.2761 - val_categorical_accuracy: 0.3478\n",
      "Epoch 190/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.1991 - categorical_accuracy: 0.9215 - val_loss: 0.6443 - val_categorical_accuracy: 0.6906\n",
      "Epoch 191/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2146 - categorical_accuracy: 0.9194 - val_loss: 0.7787 - val_categorical_accuracy: 0.7449\n",
      "Epoch 192/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2130 - categorical_accuracy: 0.9148 - val_loss: 8.8985 - val_categorical_accuracy: 0.1077\n",
      "Epoch 193/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2180 - categorical_accuracy: 0.9150 - val_loss: 0.7457 - val_categorical_accuracy: 0.6601\n",
      "Epoch 194/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2384 - categorical_accuracy: 0.9106 - val_loss: 0.4042 - val_categorical_accuracy: 0.8158\n",
      "Epoch 195/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2122 - categorical_accuracy: 0.9167 - val_loss: 3.5941 - val_categorical_accuracy: 0.0982\n",
      "Epoch 196/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2142 - categorical_accuracy: 0.9158 - val_loss: 13.1029 - val_categorical_accuracy: 0.0258\n",
      "Epoch 197/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2144 - categorical_accuracy: 0.9189 - val_loss: 0.3581 - val_categorical_accuracy: 0.8361\n",
      "Epoch 198/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2129 - categorical_accuracy: 0.9159 - val_loss: 14.0002 - val_categorical_accuracy: 0.0070\n",
      "Epoch 199/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2251 - categorical_accuracy: 0.9136 - val_loss: 0.2138 - val_categorical_accuracy: 0.9054\n",
      "Epoch 200/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2225 - categorical_accuracy: 0.9147 - val_loss: 0.7019 - val_categorical_accuracy: 0.6966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23b09766d68>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x = X_train, y = y_train, epochs = 200, batch_size = 64,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 0s 29us/step\n",
      "Loss = 0.7018723562809398\n",
      "Test Accuracy = 0.6965966691810843\n"
     ]
    }
   ],
   "source": [
    "preds = classifier.evaluate(x = X_test, y = y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
