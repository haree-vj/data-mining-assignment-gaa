{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hareevarshan\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('football_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_Id</th>\n",
       "      <th>Player_name</th>\n",
       "      <th>Session_Id</th>\n",
       "      <th>Session_date</th>\n",
       "      <th>Session_Start</th>\n",
       "      <th>Session_End</th>\n",
       "      <th>Derived_kpi_Id</th>\n",
       "      <th>splitId</th>\n",
       "      <th>Session_type</th>\n",
       "      <th>Player_position</th>\n",
       "      <th>...</th>\n",
       "      <th>MetabolicPowerZone6Distance</th>\n",
       "      <th>MetabolicPowerZone1Time</th>\n",
       "      <th>MetabolicPowerZone2Time</th>\n",
       "      <th>MetabolicPowerZone3Time</th>\n",
       "      <th>MetabolicPowerZone4Time</th>\n",
       "      <th>MetabolicPowerZone5Time</th>\n",
       "      <th>MetabolicPowerZone6Time</th>\n",
       "      <th>HighIntensityBurstNumber</th>\n",
       "      <th>HighIntensityBurstDuration</th>\n",
       "      <th>RPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>cormac.costello</td>\n",
       "      <td>125</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>15318</td>\n",
       "      <td>866</td>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>11.61</td>\n",
       "      <td>487.0</td>\n",
       "      <td>174.2</td>\n",
       "      <td>30.4</td>\n",
       "      <td>18.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>24.1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>darren.daly</td>\n",
       "      <td>125</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>15326</td>\n",
       "      <td>866</td>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>12.88</td>\n",
       "      <td>449.7</td>\n",
       "      <td>171.5</td>\n",
       "      <td>35.2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1</td>\n",
       "      <td>17.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>michael.fitzsimons</td>\n",
       "      <td>125</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>15327</td>\n",
       "      <td>854</td>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>193.19</td>\n",
       "      <td>5156.3</td>\n",
       "      <td>1068.7</td>\n",
       "      <td>258.9</td>\n",
       "      <td>217.6</td>\n",
       "      <td>133.4</td>\n",
       "      <td>41.1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>michael.fitzsimons</td>\n",
       "      <td>125</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>15328</td>\n",
       "      <td>855</td>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.03</td>\n",
       "      <td>285.6</td>\n",
       "      <td>101.1</td>\n",
       "      <td>82.8</td>\n",
       "      <td>71.1</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>michael.fitzsimons</td>\n",
       "      <td>125</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>15329</td>\n",
       "      <td>856</td>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11.82</td>\n",
       "      <td>2303.2</td>\n",
       "      <td>126.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player_Id         Player_name  Session_Id Session_date Session_Start  \\\n",
       "0         10     cormac.costello         125   20-08-2016    20-08-2016   \n",
       "1         13         darren.daly         125   20-08-2016    20-08-2016   \n",
       "2         14  michael.fitzsimons         125   20-08-2016    20-08-2016   \n",
       "3         14  michael.fitzsimons         125   20-08-2016    20-08-2016   \n",
       "4         14  michael.fitzsimons         125   20-08-2016    20-08-2016   \n",
       "\n",
       "  Session_End  Derived_kpi_Id  splitId   Session_type  Player_position ...   \\\n",
       "0  20-08-2016           15318      866  Pitch Session                6 ...    \n",
       "1  20-08-2016           15326      866  Pitch Session                2 ...    \n",
       "2  20-08-2016           15327      854  Pitch Session                2 ...    \n",
       "3  20-08-2016           15328      855  Pitch Session                2 ...    \n",
       "4  20-08-2016           15329      856  Pitch Session                2 ...    \n",
       "\n",
       "   MetabolicPowerZone6Distance  MetabolicPowerZone1Time  \\\n",
       "0                        11.61                    487.0   \n",
       "1                        12.88                    449.7   \n",
       "2                       193.19                   5156.3   \n",
       "3                         5.03                    285.6   \n",
       "4                        11.82                   2303.2   \n",
       "\n",
       "   MetabolicPowerZone2Time  MetabolicPowerZone3Time  MetabolicPowerZone4Time  \\\n",
       "0                    174.2                     30.4                     18.5   \n",
       "1                    171.5                     35.2                     22.0   \n",
       "2                   1068.7                    258.9                    217.6   \n",
       "3                    101.1                     82.8                     71.1   \n",
       "4                    126.0                     14.1                     22.4   \n",
       "\n",
       "   MetabolicPowerZone5Time  MetabolicPowerZone6Time  HighIntensityBurstNumber  \\\n",
       "0                     12.0                      2.6                         2   \n",
       "1                     13.0                      3.7                         1   \n",
       "2                    133.4                     41.1                         1   \n",
       "3                     24.2                      1.2                         0   \n",
       "4                     16.0                      3.1                         0   \n",
       "\n",
       "   HighIntensityBurstDuration  RPE  \n",
       "0                        24.1    4  \n",
       "1                        17.3    4  \n",
       "2                        35.4    4  \n",
       "3                         0.0    4  \n",
       "4                         0.0    4  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset['RTT_plus_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset['updated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player_Id</th>\n",
       "      <th>Player_name</th>\n",
       "      <th>Session_Id</th>\n",
       "      <th>Session_date</th>\n",
       "      <th>Session_Start</th>\n",
       "      <th>Session_End</th>\n",
       "      <th>Derived_kpi_Id</th>\n",
       "      <th>splitId</th>\n",
       "      <th>Session_type</th>\n",
       "      <th>Player_position</th>\n",
       "      <th>...</th>\n",
       "      <th>RPE_1</th>\n",
       "      <th>RPE_2</th>\n",
       "      <th>RPE_3</th>\n",
       "      <th>RPE_4</th>\n",
       "      <th>RPE_5</th>\n",
       "      <th>RPE_6</th>\n",
       "      <th>RPE_7</th>\n",
       "      <th>RPE_8</th>\n",
       "      <th>RPE_9</th>\n",
       "      <th>RPE_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>cormac.costello</td>\n",
       "      <td>125</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>15318</td>\n",
       "      <td>866</td>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>darren.daly</td>\n",
       "      <td>125</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>15326</td>\n",
       "      <td>866</td>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>michael.fitzsimons</td>\n",
       "      <td>125</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>15327</td>\n",
       "      <td>854</td>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>michael.fitzsimons</td>\n",
       "      <td>125</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>15328</td>\n",
       "      <td>855</td>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>michael.fitzsimons</td>\n",
       "      <td>125</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>20-08-2016</td>\n",
       "      <td>15329</td>\n",
       "      <td>856</td>\n",
       "      <td>Pitch Session</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player_Id         Player_name  Session_Id Session_date Session_Start  \\\n",
       "0         10     cormac.costello         125   20-08-2016    20-08-2016   \n",
       "1         13         darren.daly         125   20-08-2016    20-08-2016   \n",
       "2         14  michael.fitzsimons         125   20-08-2016    20-08-2016   \n",
       "3         14  michael.fitzsimons         125   20-08-2016    20-08-2016   \n",
       "4         14  michael.fitzsimons         125   20-08-2016    20-08-2016   \n",
       "\n",
       "  Session_End  Derived_kpi_Id  splitId   Session_type  Player_position  \\\n",
       "0  20-08-2016           15318      866  Pitch Session                6   \n",
       "1  20-08-2016           15326      866  Pitch Session                2   \n",
       "2  20-08-2016           15327      854  Pitch Session                2   \n",
       "3  20-08-2016           15328      855  Pitch Session                2   \n",
       "4  20-08-2016           15329      856  Pitch Session                2   \n",
       "\n",
       "    ...    RPE_1  RPE_2  RPE_3  RPE_4  RPE_5  RPE_6  RPE_7  RPE_8  RPE_9  \\\n",
       "0   ...        0      0      0      1      0      0      0      0      0   \n",
       "1   ...        0      0      0      1      0      0      0      0      0   \n",
       "2   ...        0      0      0      1      0      0      0      0      0   \n",
       "3   ...        0      0      0      1      0      0      0      0      0   \n",
       "4   ...        0      0      0      1      0      0      0      0      0   \n",
       "\n",
       "   RPE_10  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"RPE\"] =dataset[\"RPE\"].astype(int)\n",
    "dataset = pd.get_dummies(dataset, columns=[\"RPE\"])\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20711, 120)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,8:109].values # first columns\n",
    "y = dataset.iloc[:,110:].values # last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pitch Session', 6, 80, 320, 0.77, 0.79, 602.33, 602.33, 374.85,\n",
       "       135.43, 41.58, 42.89, 7.57, 0.0, 0.83, 6.05, 26.91, 15.54, 6.19,\n",
       "       2.16, 2.52, 0.51, 0.0, 53.05, 2.67, 4.19, 4.87, 6.37, 4.98, 29.96,\n",
       "       15.04, 60.1, 455.8, 160.3, 48.5, 0.0, 0.0, 217, 116, 52, 20, 11, 4,\n",
       "       14, 0, 4, 84, 58, 126, 74, 539.81, 169.01, 356.93, 713.27, 4.28,\n",
       "       282.91, 62.51, 146.15, 339.32, 3.82, 0.11, 13, 55, 14, 1, 1, 0, 5,\n",
       "       31, 11, 9, 2, 0, 64.0, 4.62, 724.7, 49.87, 56.14, 720.71, 169.0,\n",
       "       12.12706908, 6.41385, 4.809375, 6.771875, 9.017366842000001,\n",
       "       133.35, 14.6, 196.85, 235.99, 60.34, 53.01, 44.53, 11.61, 487.0,\n",
       "       174.2, 30.4, 18.5, 12.0, 2.6, 2, 24.1], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "X[:, 0] = labelencoder.fit_transform(X[:, 0])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.normalize(X, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16568, 103) (16568, 10) (4143, 103) (4143, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=30, kernel_initializer = 'uniform', activation = 'relu', input_dim=103))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=30, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n",
    "classifier.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=40, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n",
    "classifier.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(10,bias_initializer='zeros'))\n",
    "classifier.add(BatchNormalization(momentum=0.99, epsilon=0.001))\n",
    "classifier.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                3120      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 40)                1240      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 6,140\n",
      "Trainable params: 5,920\n",
      "Non-trainable params: 220\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = \"categorical_crossentropy\", metrics = [\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16568 samples, validate on 4143 samples\n",
      "Epoch 1/200\n",
      "16568/16568 [==============================] - 2s 115us/step - loss: 1.8462 - categorical_accuracy: 0.3213 - val_loss: 5.5491 - val_categorical_accuracy: 0.1212\n",
      "Epoch 2/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 1.2487 - categorical_accuracy: 0.5896 - val_loss: 2.0298 - val_categorical_accuracy: 0.1538\n",
      "Epoch 3/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.9943 - categorical_accuracy: 0.6846 - val_loss: 3.4125 - val_categorical_accuracy: 0.0560\n",
      "Epoch 4/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.8143 - categorical_accuracy: 0.7526 - val_loss: 4.3881 - val_categorical_accuracy: 0.1209\n",
      "Epoch 5/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.7274 - categorical_accuracy: 0.7750 - val_loss: 3.3666 - val_categorical_accuracy: 0.0958\n",
      "Epoch 6/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.6788 - categorical_accuracy: 0.7802 - val_loss: 0.5778 - val_categorical_accuracy: 0.8045\n",
      "Epoch 7/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.6505 - categorical_accuracy: 0.7831 - val_loss: 0.5613 - val_categorical_accuracy: 0.8100\n",
      "Epoch 8/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.6083 - categorical_accuracy: 0.7961 - val_loss: 2.1464 - val_categorical_accuracy: 0.2146\n",
      "Epoch 9/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.5680 - categorical_accuracy: 0.8092 - val_loss: 9.7168 - val_categorical_accuracy: 0.0126\n",
      "Epoch 10/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.5713 - categorical_accuracy: 0.8022 - val_loss: 4.4338 - val_categorical_accuracy: 0.0644\n",
      "Epoch 11/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.5600 - categorical_accuracy: 0.8042 - val_loss: 4.2885 - val_categorical_accuracy: 0.0582\n",
      "Epoch 12/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.4980 - categorical_accuracy: 0.8288 - val_loss: 7.7130 - val_categorical_accuracy: 0.0072\n",
      "Epoch 13/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.5065 - categorical_accuracy: 0.8239 - val_loss: 0.3542 - val_categorical_accuracy: 0.8554\n",
      "Epoch 14/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.4747 - categorical_accuracy: 0.8347 - val_loss: 1.2381 - val_categorical_accuracy: 0.5938\n",
      "Epoch 15/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4796 - categorical_accuracy: 0.8321 - val_loss: 0.8680 - val_categorical_accuracy: 0.7277\n",
      "Epoch 16/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4577 - categorical_accuracy: 0.8358 - val_loss: 0.8148 - val_categorical_accuracy: 0.6662\n",
      "Epoch 17/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4685 - categorical_accuracy: 0.8363 - val_loss: 0.1810 - val_categorical_accuracy: 0.9382\n",
      "Epoch 18/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4597 - categorical_accuracy: 0.8356 - val_loss: 0.9320 - val_categorical_accuracy: 0.6184\n",
      "Epoch 19/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.4415 - categorical_accuracy: 0.8410 - val_loss: 2.8742 - val_categorical_accuracy: 0.2228\n",
      "Epoch 20/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.4159 - categorical_accuracy: 0.8524 - val_loss: 9.3653 - val_categorical_accuracy: 0.0253\n",
      "Epoch 21/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.4167 - categorical_accuracy: 0.8500 - val_loss: 1.8301 - val_categorical_accuracy: 0.4306\n",
      "Epoch 22/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.4165 - categorical_accuracy: 0.8527 - val_loss: 9.5418 - val_categorical_accuracy: 0.0075\n",
      "Epoch 23/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.3996 - categorical_accuracy: 0.8570 - val_loss: 1.4446 - val_categorical_accuracy: 0.4912\n",
      "Epoch 24/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.4050 - categorical_accuracy: 0.8565 - val_loss: 5.0535 - val_categorical_accuracy: 0.0273\n",
      "Epoch 25/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.4431 - categorical_accuracy: 0.8362 - val_loss: 0.8085 - val_categorical_accuracy: 0.6307\n",
      "Epoch 26/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.4142 - categorical_accuracy: 0.8514 - val_loss: 0.1412 - val_categorical_accuracy: 0.9471\n",
      "Epoch 27/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3912 - categorical_accuracy: 0.8588 - val_loss: 0.1780 - val_categorical_accuracy: 0.9341\n",
      "Epoch 28/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3787 - categorical_accuracy: 0.8658 - val_loss: 0.1027 - val_categorical_accuracy: 0.9582\n",
      "Epoch 29/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3684 - categorical_accuracy: 0.8640 - val_loss: 1.5252 - val_categorical_accuracy: 0.3500\n",
      "Epoch 30/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3481 - categorical_accuracy: 0.8725 - val_loss: 0.1094 - val_categorical_accuracy: 0.9546\n",
      "Epoch 31/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3984 - categorical_accuracy: 0.8574 - val_loss: 0.4673 - val_categorical_accuracy: 0.7789\n",
      "Epoch 32/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.3455 - categorical_accuracy: 0.8731 - val_loss: 8.1315 - val_categorical_accuracy: 0.0075\n",
      "Epoch 33/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3884 - categorical_accuracy: 0.8594 - val_loss: 0.1331 - val_categorical_accuracy: 0.9392\n",
      "Epoch 34/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3413 - categorical_accuracy: 0.8772 - val_loss: 1.1234 - val_categorical_accuracy: 0.5532\n",
      "Epoch 35/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.3545 - categorical_accuracy: 0.8693 - val_loss: 0.1130 - val_categorical_accuracy: 0.9522\n",
      "Epoch 36/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3564 - categorical_accuracy: 0.8662 - val_loss: 0.1462 - val_categorical_accuracy: 0.9319\n",
      "Epoch 37/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3464 - categorical_accuracy: 0.8724 - val_loss: 2.7437 - val_categorical_accuracy: 0.1064\n",
      "Epoch 38/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3515 - categorical_accuracy: 0.8707 - val_loss: 0.6091 - val_categorical_accuracy: 0.7364\n",
      "Epoch 39/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3103 - categorical_accuracy: 0.8846 - val_loss: 0.2516 - val_categorical_accuracy: 0.8926\n",
      "Epoch 40/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3544 - categorical_accuracy: 0.8690 - val_loss: 0.3599 - val_categorical_accuracy: 0.8112\n",
      "Epoch 41/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3715 - categorical_accuracy: 0.8615 - val_loss: 0.3583 - val_categorical_accuracy: 0.8197\n",
      "Epoch 42/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3084 - categorical_accuracy: 0.8873 - val_loss: 0.1458 - val_categorical_accuracy: 0.9317\n",
      "Epoch 43/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3495 - categorical_accuracy: 0.8694 - val_loss: 1.5121 - val_categorical_accuracy: 0.4313\n",
      "Epoch 44/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3558 - categorical_accuracy: 0.8713 - val_loss: 0.4356 - val_categorical_accuracy: 0.8238\n",
      "Epoch 45/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3708 - categorical_accuracy: 0.8611 - val_loss: 3.2630 - val_categorical_accuracy: 0.1692\n",
      "Epoch 46/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3214 - categorical_accuracy: 0.8806 - val_loss: 1.9381 - val_categorical_accuracy: 0.3160\n",
      "Epoch 47/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3250 - categorical_accuracy: 0.8817 - val_loss: 6.6335 - val_categorical_accuracy: 0.0693\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3094 - categorical_accuracy: 0.8853 - val_loss: 6.3936 - val_categorical_accuracy: 0.0406\n",
      "Epoch 49/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.4019 - categorical_accuracy: 0.8472 - val_loss: 2.3737 - val_categorical_accuracy: 0.3135\n",
      "Epoch 50/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.3273 - categorical_accuracy: 0.8775 - val_loss: 9.8822 - val_categorical_accuracy: 0.0075\n",
      "Epoch 51/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.3290 - categorical_accuracy: 0.8775 - val_loss: 0.0807 - val_categorical_accuracy: 0.9626\n",
      "Epoch 52/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3138 - categorical_accuracy: 0.8834 - val_loss: 0.6741 - val_categorical_accuracy: 0.6669\n",
      "Epoch 53/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3532 - categorical_accuracy: 0.8693 - val_loss: 0.1147 - val_categorical_accuracy: 0.9462\n",
      "Epoch 54/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3072 - categorical_accuracy: 0.8865 - val_loss: 0.2328 - val_categorical_accuracy: 0.9018\n",
      "Epoch 55/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.3121 - categorical_accuracy: 0.8844 - val_loss: 7.2972 - val_categorical_accuracy: 0.0292\n",
      "Epoch 56/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2922 - categorical_accuracy: 0.8906 - val_loss: 0.2588 - val_categorical_accuracy: 0.8921\n",
      "Epoch 57/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3257 - categorical_accuracy: 0.8813 - val_loss: 2.0582 - val_categorical_accuracy: 0.4955\n",
      "Epoch 58/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3138 - categorical_accuracy: 0.8804 - val_loss: 0.3599 - val_categorical_accuracy: 0.8429\n",
      "Epoch 59/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2994 - categorical_accuracy: 0.8873 - val_loss: 0.0939 - val_categorical_accuracy: 0.9616\n",
      "Epoch 60/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2846 - categorical_accuracy: 0.8941 - val_loss: 3.6552 - val_categorical_accuracy: 0.3290\n",
      "Epoch 61/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3156 - categorical_accuracy: 0.8817 - val_loss: 3.8799 - val_categorical_accuracy: 0.1994\n",
      "Epoch 62/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3424 - categorical_accuracy: 0.8710 - val_loss: 4.3317 - val_categorical_accuracy: 0.2201\n",
      "Epoch 63/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.3226 - categorical_accuracy: 0.8763 - val_loss: 2.0105 - val_categorical_accuracy: 0.5819\n",
      "Epoch 64/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3055 - categorical_accuracy: 0.8874 - val_loss: 2.7684 - val_categorical_accuracy: 0.0698\n",
      "Epoch 65/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3166 - categorical_accuracy: 0.8810 - val_loss: 0.0883 - val_categorical_accuracy: 0.9587\n",
      "Epoch 66/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2774 - categorical_accuracy: 0.8946 - val_loss: 1.9108 - val_categorical_accuracy: 0.3876\n",
      "Epoch 67/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2781 - categorical_accuracy: 0.8981 - val_loss: 1.7167 - val_categorical_accuracy: 0.6519\n",
      "Epoch 68/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2972 - categorical_accuracy: 0.8876 - val_loss: 0.0784 - val_categorical_accuracy: 0.9573\n",
      "Epoch 69/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2797 - categorical_accuracy: 0.8919 - val_loss: 0.1498 - val_categorical_accuracy: 0.9327\n",
      "Epoch 70/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2859 - categorical_accuracy: 0.8952 - val_loss: 0.1185 - val_categorical_accuracy: 0.9498\n",
      "Epoch 71/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3111 - categorical_accuracy: 0.8848 - val_loss: 6.1617 - val_categorical_accuracy: 0.1221\n",
      "Epoch 72/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2720 - categorical_accuracy: 0.8980 - val_loss: 8.1200 - val_categorical_accuracy: 0.0084\n",
      "Epoch 73/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2912 - categorical_accuracy: 0.8911 - val_loss: 0.1612 - val_categorical_accuracy: 0.9208\n",
      "Epoch 74/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3021 - categorical_accuracy: 0.8864 - val_loss: 3.9462 - val_categorical_accuracy: 0.1299\n",
      "Epoch 75/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3018 - categorical_accuracy: 0.8892 - val_loss: 8.3181 - val_categorical_accuracy: 0.0092\n",
      "Epoch 76/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.3082 - categorical_accuracy: 0.8853 - val_loss: 7.4554 - val_categorical_accuracy: 0.0268\n",
      "Epoch 77/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2835 - categorical_accuracy: 0.8961 - val_loss: 1.2836 - val_categorical_accuracy: 0.5062\n",
      "Epoch 78/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2887 - categorical_accuracy: 0.8926 - val_loss: 0.0796 - val_categorical_accuracy: 0.9575\n",
      "Epoch 79/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3363 - categorical_accuracy: 0.8777 - val_loss: 0.1416 - val_categorical_accuracy: 0.9365\n",
      "Epoch 80/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2974 - categorical_accuracy: 0.8857 - val_loss: 0.0887 - val_categorical_accuracy: 0.9556\n",
      "Epoch 81/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.3230 - categorical_accuracy: 0.8804 - val_loss: 0.2709 - val_categorical_accuracy: 0.9191\n",
      "Epoch 82/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2681 - categorical_accuracy: 0.8962 - val_loss: 0.1501 - val_categorical_accuracy: 0.9194\n",
      "Epoch 83/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2803 - categorical_accuracy: 0.8960 - val_loss: 0.1300 - val_categorical_accuracy: 0.9315\n",
      "Epoch 84/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2792 - categorical_accuracy: 0.8923 - val_loss: 0.1832 - val_categorical_accuracy: 0.9167\n",
      "Epoch 85/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2612 - categorical_accuracy: 0.9030 - val_loss: 8.8935 - val_categorical_accuracy: 0.0150\n",
      "Epoch 86/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.2589 - categorical_accuracy: 0.9014 - val_loss: 3.9824 - val_categorical_accuracy: 0.0893\n",
      "Epoch 87/200\n",
      "16568/16568 [==============================] - 1s 46us/step - loss: 0.2870 - categorical_accuracy: 0.8903 - val_loss: 6.4350 - val_categorical_accuracy: 0.0258\n",
      "Epoch 88/200\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.2599 - categorical_accuracy: 0.9017 - val_loss: 9.9312 - val_categorical_accuracy: 0.0406\n",
      "Epoch 89/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2644 - categorical_accuracy: 0.8985 - val_loss: 0.5371 - val_categorical_accuracy: 0.7697\n",
      "Epoch 90/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.2927 - categorical_accuracy: 0.8905 - val_loss: 7.5418 - val_categorical_accuracy: 0.0232\n",
      "Epoch 91/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2932 - categorical_accuracy: 0.8924 - val_loss: 3.9469 - val_categorical_accuracy: 0.2399\n",
      "Epoch 92/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2852 - categorical_accuracy: 0.8904 - val_loss: 12.3519 - val_categorical_accuracy: 0.0072\n",
      "Epoch 93/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.3187 - categorical_accuracy: 0.8776 - val_loss: 3.6492 - val_categorical_accuracy: 0.3181\n",
      "Epoch 94/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2902 - categorical_accuracy: 0.8903 - val_loss: 5.7918 - val_categorical_accuracy: 0.0275\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2597 - categorical_accuracy: 0.9013 - val_loss: 0.3275 - val_categorical_accuracy: 0.8837\n",
      "Epoch 96/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2868 - categorical_accuracy: 0.8947 - val_loss: 11.9941 - val_categorical_accuracy: 0.0075\n",
      "Epoch 97/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2911 - categorical_accuracy: 0.8923 - val_loss: 9.0122 - val_categorical_accuracy: 0.0080\n",
      "Epoch 98/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2524 - categorical_accuracy: 0.9039 - val_loss: 0.9321 - val_categorical_accuracy: 0.6894\n",
      "Epoch 99/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2678 - categorical_accuracy: 0.8968 - val_loss: 1.3877 - val_categorical_accuracy: 0.4919\n",
      "Epoch 100/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2979 - categorical_accuracy: 0.8859 - val_loss: 0.2335 - val_categorical_accuracy: 0.8926\n",
      "Epoch 101/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2943 - categorical_accuracy: 0.8877 - val_loss: 0.1287 - val_categorical_accuracy: 0.9356\n",
      "Epoch 102/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2759 - categorical_accuracy: 0.8956 - val_loss: 6.3015 - val_categorical_accuracy: 0.0077\n",
      "Epoch 103/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2668 - categorical_accuracy: 0.9017 - val_loss: 1.5065 - val_categorical_accuracy: 0.3406\n",
      "Epoch 104/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2562 - categorical_accuracy: 0.9033 - val_loss: 0.1535 - val_categorical_accuracy: 0.9327\n",
      "Epoch 105/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2628 - categorical_accuracy: 0.8976 - val_loss: 13.7566 - val_categorical_accuracy: 0.0075\n",
      "Epoch 106/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2854 - categorical_accuracy: 0.8894 - val_loss: 0.1459 - val_categorical_accuracy: 0.9208\n",
      "Epoch 107/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2558 - categorical_accuracy: 0.8992 - val_loss: 6.2077 - val_categorical_accuracy: 0.0292\n",
      "Epoch 108/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2659 - categorical_accuracy: 0.8980 - val_loss: 3.1048 - val_categorical_accuracy: 0.1436\n",
      "Epoch 109/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2868 - categorical_accuracy: 0.8898 - val_loss: 0.3053 - val_categorical_accuracy: 0.8173\n",
      "Epoch 110/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2536 - categorical_accuracy: 0.9003 - val_loss: 2.9358 - val_categorical_accuracy: 0.3787\n",
      "Epoch 111/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2587 - categorical_accuracy: 0.8976 - val_loss: 0.1277 - val_categorical_accuracy: 0.9399\n",
      "Epoch 112/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2666 - categorical_accuracy: 0.8976 - val_loss: 9.8443 - val_categorical_accuracy: 0.0208\n",
      "Epoch 113/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2888 - categorical_accuracy: 0.8928 - val_loss: 0.5142 - val_categorical_accuracy: 0.7910\n",
      "Epoch 114/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2659 - categorical_accuracy: 0.8981 - val_loss: 0.9053 - val_categorical_accuracy: 0.6346\n",
      "Epoch 115/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2577 - categorical_accuracy: 0.9025 - val_loss: 2.3914 - val_categorical_accuracy: 0.2925\n",
      "Epoch 116/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2649 - categorical_accuracy: 0.8996 - val_loss: 6.6905 - val_categorical_accuracy: 0.0099\n",
      "Epoch 117/200\n",
      "16568/16568 [==============================] - 1s 42us/step - loss: 0.2756 - categorical_accuracy: 0.8975 - val_loss: 1.8077 - val_categorical_accuracy: 0.4364\n",
      "Epoch 118/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2901 - categorical_accuracy: 0.8918 - val_loss: 0.4346 - val_categorical_accuracy: 0.7661\n",
      "Epoch 119/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2561 - categorical_accuracy: 0.9016 - val_loss: 1.2636 - val_categorical_accuracy: 0.5764\n",
      "Epoch 120/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2437 - categorical_accuracy: 0.9073 - val_loss: 13.1603 - val_categorical_accuracy: 0.0072\n",
      "Epoch 121/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2643 - categorical_accuracy: 0.8997 - val_loss: 0.4758 - val_categorical_accuracy: 0.7702\n",
      "Epoch 122/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2837 - categorical_accuracy: 0.8946 - val_loss: 1.1309 - val_categorical_accuracy: 0.5030\n",
      "Epoch 123/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2550 - categorical_accuracy: 0.8995 - val_loss: 0.7190 - val_categorical_accuracy: 0.6993\n",
      "Epoch 124/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2776 - categorical_accuracy: 0.8936 - val_loss: 0.5803 - val_categorical_accuracy: 0.7630\n",
      "Epoch 125/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2645 - categorical_accuracy: 0.9022 - val_loss: 7.7201 - val_categorical_accuracy: 0.0343\n",
      "Epoch 126/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2475 - categorical_accuracy: 0.9048 - val_loss: 2.4711 - val_categorical_accuracy: 0.2991\n",
      "Epoch 127/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2832 - categorical_accuracy: 0.8917 - val_loss: 3.3774 - val_categorical_accuracy: 0.3686\n",
      "Epoch 128/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2600 - categorical_accuracy: 0.9014 - val_loss: 3.9590 - val_categorical_accuracy: 0.1212\n",
      "Epoch 129/200\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.2457 - categorical_accuracy: 0.9094 - val_loss: 0.4323 - val_categorical_accuracy: 0.7912\n",
      "Epoch 130/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2740 - categorical_accuracy: 0.8962 - val_loss: 0.1456 - val_categorical_accuracy: 0.9435\n",
      "Epoch 131/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2721 - categorical_accuracy: 0.8961 - val_loss: 12.0481 - val_categorical_accuracy: 0.0111\n",
      "Epoch 132/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2575 - categorical_accuracy: 0.9008 - val_loss: 1.9293 - val_categorical_accuracy: 0.2964\n",
      "Epoch 133/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2482 - categorical_accuracy: 0.9057 - val_loss: 0.9010 - val_categorical_accuracy: 0.6635\n",
      "Epoch 134/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2581 - categorical_accuracy: 0.9024 - val_loss: 3.9189 - val_categorical_accuracy: 0.3558\n",
      "Epoch 135/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2828 - categorical_accuracy: 0.8942 - val_loss: 5.2531 - val_categorical_accuracy: 0.1463\n",
      "Epoch 136/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2544 - categorical_accuracy: 0.9011 - val_loss: 5.4542 - val_categorical_accuracy: 0.2276\n",
      "Epoch 137/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.3039 - categorical_accuracy: 0.8889 - val_loss: 15.0408 - val_categorical_accuracy: 0.0070\n",
      "Epoch 138/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2534 - categorical_accuracy: 0.9039 - val_loss: 1.2075 - val_categorical_accuracy: 0.5614\n",
      "Epoch 139/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2778 - categorical_accuracy: 0.8953 - val_loss: 2.1102 - val_categorical_accuracy: 0.4658\n",
      "Epoch 140/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2434 - categorical_accuracy: 0.9042 - val_loss: 2.8700 - val_categorical_accuracy: 0.3674\n",
      "Epoch 141/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2594 - categorical_accuracy: 0.8994 - val_loss: 4.6005 - val_categorical_accuracy: 0.3312\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2473 - categorical_accuracy: 0.9062 - val_loss: 0.4767 - val_categorical_accuracy: 0.8397\n",
      "Epoch 143/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2564 - categorical_accuracy: 0.8985 - val_loss: 0.3705 - val_categorical_accuracy: 0.8383\n",
      "Epoch 144/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2603 - categorical_accuracy: 0.9031 - val_loss: 0.9287 - val_categorical_accuracy: 0.6770\n",
      "Epoch 145/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2333 - categorical_accuracy: 0.9077 - val_loss: 0.1957 - val_categorical_accuracy: 0.9100\n",
      "Epoch 146/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2562 - categorical_accuracy: 0.9043 - val_loss: 2.6595 - val_categorical_accuracy: 0.4282\n",
      "Epoch 147/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2921 - categorical_accuracy: 0.8912 - val_loss: 15.2145 - val_categorical_accuracy: 0.0070\n",
      "Epoch 148/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2780 - categorical_accuracy: 0.8999 - val_loss: 0.9761 - val_categorical_accuracy: 0.6406\n",
      "Epoch 149/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2515 - categorical_accuracy: 0.9037 - val_loss: 4.3496 - val_categorical_accuracy: 0.0992\n",
      "Epoch 150/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2395 - categorical_accuracy: 0.9092 - val_loss: 3.2045 - val_categorical_accuracy: 0.1752\n",
      "Epoch 151/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2465 - categorical_accuracy: 0.9072 - val_loss: 8.1957 - val_categorical_accuracy: 0.0256\n",
      "Epoch 152/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2587 - categorical_accuracy: 0.9010 - val_loss: 5.5542 - val_categorical_accuracy: 0.1007\n",
      "Epoch 153/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2662 - categorical_accuracy: 0.8980 - val_loss: 3.5159 - val_categorical_accuracy: 0.2180\n",
      "Epoch 154/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2327 - categorical_accuracy: 0.9097 - val_loss: 0.7586 - val_categorical_accuracy: 0.7116\n",
      "Epoch 155/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2628 - categorical_accuracy: 0.9002 - val_loss: 2.0240 - val_categorical_accuracy: 0.4743\n",
      "Epoch 156/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2480 - categorical_accuracy: 0.9034 - val_loss: 0.3100 - val_categorical_accuracy: 0.8535\n",
      "Epoch 157/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2483 - categorical_accuracy: 0.9037 - val_loss: 10.5452 - val_categorical_accuracy: 0.0253\n",
      "Epoch 158/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2463 - categorical_accuracy: 0.9029 - val_loss: 4.9189 - val_categorical_accuracy: 0.0743\n",
      "Epoch 159/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2505 - categorical_accuracy: 0.9025 - val_loss: 0.3198 - val_categorical_accuracy: 0.8298\n",
      "Epoch 160/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2325 - categorical_accuracy: 0.9102 - val_loss: 1.2926 - val_categorical_accuracy: 0.6826\n",
      "Epoch 161/200\n",
      "16568/16568 [==============================] - 1s 44us/step - loss: 0.2657 - categorical_accuracy: 0.8985 - val_loss: 0.2746 - val_categorical_accuracy: 0.8624\n",
      "Epoch 162/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2551 - categorical_accuracy: 0.9008 - val_loss: 8.7017 - val_categorical_accuracy: 0.0261\n",
      "Epoch 163/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2690 - categorical_accuracy: 0.8974 - val_loss: 3.3554 - val_categorical_accuracy: 0.3418\n",
      "Epoch 164/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2590 - categorical_accuracy: 0.9032 - val_loss: 12.3079 - val_categorical_accuracy: 0.0099\n",
      "Epoch 165/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2724 - categorical_accuracy: 0.8970 - val_loss: 2.3319 - val_categorical_accuracy: 0.2723\n",
      "Epoch 166/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2265 - categorical_accuracy: 0.9168 - val_loss: 0.3058 - val_categorical_accuracy: 0.8412\n",
      "Epoch 167/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2573 - categorical_accuracy: 0.9003 - val_loss: 0.7812 - val_categorical_accuracy: 0.6418\n",
      "Epoch 168/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2542 - categorical_accuracy: 0.9023 - val_loss: 4.7297 - val_categorical_accuracy: 0.0171\n",
      "Epoch 169/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2523 - categorical_accuracy: 0.9023 - val_loss: 0.1698 - val_categorical_accuracy: 0.9522\n",
      "Epoch 170/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2323 - categorical_accuracy: 0.9093 - val_loss: 2.1175 - val_categorical_accuracy: 0.4451\n",
      "Epoch 171/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2546 - categorical_accuracy: 0.9029 - val_loss: 4.5525 - val_categorical_accuracy: 0.2701\n",
      "Epoch 172/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2966 - categorical_accuracy: 0.8903 - val_loss: 1.1446 - val_categorical_accuracy: 0.5844\n",
      "Epoch 173/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2407 - categorical_accuracy: 0.9048 - val_loss: 9.3540 - val_categorical_accuracy: 0.1388\n",
      "Epoch 174/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2319 - categorical_accuracy: 0.9096 - val_loss: 0.3259 - val_categorical_accuracy: 0.8301\n",
      "Epoch 175/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2475 - categorical_accuracy: 0.9059 - val_loss: 5.5598 - val_categorical_accuracy: 0.2168\n",
      "Epoch 176/200\n",
      "16568/16568 [==============================] - 1s 43us/step - loss: 0.2312 - categorical_accuracy: 0.9104 - val_loss: 10.3505 - val_categorical_accuracy: 0.1687\n",
      "Epoch 177/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2566 - categorical_accuracy: 0.9022 - val_loss: 1.0407 - val_categorical_accuracy: 0.6601\n",
      "Epoch 178/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2467 - categorical_accuracy: 0.9068 - val_loss: 0.1063 - val_categorical_accuracy: 0.9640\n",
      "Epoch 179/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2250 - categorical_accuracy: 0.9121 - val_loss: 1.7343 - val_categorical_accuracy: 0.3476\n",
      "Epoch 180/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2759 - categorical_accuracy: 0.8940 - val_loss: 1.6518 - val_categorical_accuracy: 0.4420\n",
      "Epoch 181/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2336 - categorical_accuracy: 0.9097 - val_loss: 6.5332 - val_categorical_accuracy: 0.0249\n",
      "Epoch 182/200\n",
      "16568/16568 [==============================] - 1s 37us/step - loss: 0.2182 - categorical_accuracy: 0.9150 - val_loss: 0.2327 - val_categorical_accuracy: 0.8882\n",
      "Epoch 183/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2761 - categorical_accuracy: 0.8955 - val_loss: 0.6494 - val_categorical_accuracy: 0.6676\n",
      "Epoch 184/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2483 - categorical_accuracy: 0.9043 - val_loss: 1.0987 - val_categorical_accuracy: 0.5457\n",
      "Epoch 185/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2475 - categorical_accuracy: 0.9049 - val_loss: 6.0849 - val_categorical_accuracy: 0.0311\n",
      "Epoch 186/200\n",
      "16568/16568 [==============================] - 1s 41us/step - loss: 0.2313 - categorical_accuracy: 0.9110 - val_loss: 0.6240 - val_categorical_accuracy: 0.7217\n",
      "Epoch 187/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2412 - categorical_accuracy: 0.9069 - val_loss: 0.7602 - val_categorical_accuracy: 0.6713\n",
      "Epoch 188/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2528 - categorical_accuracy: 0.9036 - val_loss: 0.7949 - val_categorical_accuracy: 0.6447\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2407 - categorical_accuracy: 0.9075 - val_loss: 3.5267 - val_categorical_accuracy: 0.2356\n",
      "Epoch 190/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2543 - categorical_accuracy: 0.9026 - val_loss: 0.2482 - val_categorical_accuracy: 0.8870\n",
      "Epoch 191/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2369 - categorical_accuracy: 0.9099 - val_loss: 10.9893 - val_categorical_accuracy: 0.0251\n",
      "Epoch 192/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2449 - categorical_accuracy: 0.9073 - val_loss: 13.5521 - val_categorical_accuracy: 0.0070\n",
      "Epoch 193/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2532 - categorical_accuracy: 0.9045 - val_loss: 3.7702 - val_categorical_accuracy: 0.1513\n",
      "Epoch 194/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2780 - categorical_accuracy: 0.8961 - val_loss: 0.2428 - val_categorical_accuracy: 0.8897\n",
      "Epoch 195/200\n",
      "16568/16568 [==============================] - 1s 38us/step - loss: 0.2203 - categorical_accuracy: 0.9145 - val_loss: 13.5750 - val_categorical_accuracy: 0.0099\n",
      "Epoch 196/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2406 - categorical_accuracy: 0.9067 - val_loss: 4.6290 - val_categorical_accuracy: 0.0707\n",
      "Epoch 197/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2508 - categorical_accuracy: 0.9059 - val_loss: 4.3578 - val_categorical_accuracy: 0.0278\n",
      "Epoch 198/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2492 - categorical_accuracy: 0.9075 - val_loss: 3.6173 - val_categorical_accuracy: 0.2032\n",
      "Epoch 199/200\n",
      "16568/16568 [==============================] - 1s 39us/step - loss: 0.2450 - categorical_accuracy: 0.9063 - val_loss: 0.1164 - val_categorical_accuracy: 0.9413\n",
      "Epoch 200/200\n",
      "16568/16568 [==============================] - 1s 40us/step - loss: 0.2488 - categorical_accuracy: 0.9016 - val_loss: 1.6855 - val_categorical_accuracy: 0.5687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25b681d8d68>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x = X_train, y = y_train, epochs = 200, batch_size = 64,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 0s 24us/step\n",
      "Loss = 1.6854916979315313\n",
      "Test Accuracy = 0.568670045867681\n"
     ]
    }
   ],
   "source": [
    "preds = classifier.evaluate(x = X_test, y = y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
